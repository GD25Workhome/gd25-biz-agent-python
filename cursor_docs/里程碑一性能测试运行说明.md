# 里程碑一：性能基准测试运行说明

## 概述

里程碑一（M5.3.1）的性能测试需要在实际运行的应用环境中进行，因为需要测试完整的请求处理流程。本文档说明如何运行性能测试。

## 前置条件

1. **应用已启动**：确保应用可以通过 `uvicorn app.main:app` 正常启动
2. **数据库已配置**：确保数据库连接正常
3. **Langfuse 配置**（可选）：如果要测试 Langfuse 集成，需要配置 Langfuse 服务

## 测试方法

### 方法一：使用测试脚本（推荐）

测试脚本位于：`cursor_test/M5_test/langfuse/test_performance.py`

**注意**：由于性能测试需要完整的应用环境，测试脚本需要应用已经初始化。如果直接运行 pytest 失败，请使用方法二。

### 方法二：手动运行性能测试

#### 1. 启动应用

```bash
# 在项目根目录
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

#### 2. 运行性能测试脚本

创建一个独立的性能测试脚本（`cursor_test/M5_test/langfuse/run_performance_test.py`）：

```python
"""
性能测试运行脚本
需要应用已经启动并运行在 http://localhost:8000
"""
import requests
import time
import statistics
from typing import List

def send_chat_request(message: str, session_id: str, user_id: str) -> float:
    """发送聊天请求并返回响应时间"""
    url = "http://localhost:8000/api/v1/chat"
    data = {
        "message": message,
        "session_id": session_id,
        "user_id": user_id
    }
    
    start_time = time.time()
    response = requests.post(url, json=data)
    end_time = time.time()
    
    response_time = end_time - start_time
    
    if response.status_code == 200:
        print(f"✅ 请求成功，响应时间: {response_time:.3f} 秒")
    else:
        print(f"❌ 请求失败: {response.status_code}, {response.text}")
    
    return response_time

def run_baseline_test(num_requests: int = 10):
    """运行基准测试"""
    print(f"\n开始基准测试（{num_requests} 个请求）...")
    
    response_times = []
    for i in range(num_requests):
        response_time = send_chat_request(
            message=f"测试消息 {i+1}",
            session_id=f"test_session_{i}",
            user_id=f"test_user_{i}"
        )
        response_times.append(response_time)
        time.sleep(0.1)  # 避免请求过快
    
    # 计算统计信息
    avg_time = statistics.mean(response_times)
    min_time = min(response_times)
    max_time = max(response_times)
    median_time = statistics.median(response_times)
    
    print(f"\n性能统计：")
    print(f"  平均响应时间: {avg_time:.3f} 秒")
    print(f"  最小响应时间: {min_time:.3f} 秒")
    print(f"  最大响应时间: {max_time:.3f} 秒")
    print(f"  中位数响应时间: {median_time:.3f} 秒")
    
    return response_times

if __name__ == "__main__":
    # 运行基准测试
    run_baseline_test(num_requests=10)
```

#### 3. 对比测试

**禁用 Langfuse**：
1. 设置环境变量 `LANGFUSE_ENABLED=False`
2. 重启应用
3. 运行性能测试脚本，记录结果

**启用 Langfuse**：
1. 设置环境变量 `LANGFUSE_ENABLED=True`
2. 配置 Langfuse 密钥和地址
3. 重启应用
4. 运行性能测试脚本，记录结果

**对比分析**：
- 计算响应时间增加百分比
- 计算吞吐量变化
- 识别性能瓶颈

## 测试指标

### 基准测试指标

- **平均响应时间**：所有请求的平均响应时间
- **最小/最大响应时间**：响应时间的范围
- **中位数响应时间**：响应时间的中位数
- **P95/P99 响应时间**：95% 和 99% 的请求的响应时间

### 压力测试指标

- **吞吐量**：每秒处理的请求数
- **并发处理能力**：同时处理的请求数
- **资源使用**：CPU 和内存使用率

### 延迟测试指标

- **主流程响应时间**：即使 Langfuse 服务慢，主流程的响应时间
- **错误隔离**：验证 Langfuse 失败不影响主流程

## 预期结果

### 性能目标

- **响应时间增加**：< 5%（启用 Langfuse 后）
- **吞吐量下降**：< 5%（启用 Langfuse 后）
- **资源使用增加**：< 10%（CPU 和内存）

### 功能目标

- **可靠性**：Langfuse 服务不可用时，主流程不受影响
- **数据完整性**：所有 Trace、Span、Generation 数据正确记录

## 注意事项

1. **测试环境**：建议在独立的测试环境中运行性能测试，避免影响生产环境
2. **数据准备**：确保测试数据充足，能够模拟真实场景
3. **网络环境**：如果 Langfuse 服务在远程，网络延迟可能影响测试结果
4. **资源监控**：运行测试时监控系统资源使用情况

## 问题排查

### 测试失败

如果测试失败，检查：
1. 应用是否正常启动
2. 数据库连接是否正常
3. LLM API 是否可访问
4. Langfuse 配置是否正确（如果启用）

### 性能异常

如果性能异常，检查：
1. 系统资源使用情况
2. 网络延迟
3. 数据库查询性能
4. LLM API 响应时间

## 下一步

完成性能测试后：
1. 记录测试结果
2. 分析性能瓶颈
3. 制定优化方案（里程碑二）
4. 更新文档标记完成状态

