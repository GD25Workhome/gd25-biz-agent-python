# 001-RAG的思考

## 一、LangChain 对 RAG 的支持与实现方式

### 1.1 RAG 基本概念

RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合信息检索和生成模型的技术，通过从外部知识库检索相关信息来增强 LLM 的生成能力，从而提高回答的准确性和相关性。

### 1.2 LangChain 对 RAG 的支持方式

LangChain 提供了完整的 RAG 实现框架，通过模块化设计支持灵活的 RAG 应用构建。

#### 1.2.1 核心组件

LangChain 的 RAG 实现主要包含以下核心组件：

1. **文档加载器（Document Loaders）**
   - `langchain_community.document_loaders`：支持多种文档格式
   - 支持 PDF、Word、HTML、Markdown、CSV、JSON 等格式
   - 支持从数据库、API、网页等数据源加载
   - 示例：`PyPDFLoader`、`TextLoader`、`CSVLoader`、`UnstructuredHTMLLoader`

2. **文本拆分器（Text Splitters）**
   - `langchain.text_splitter`：将长文本分割成适合处理的块
   - 支持多种分割策略：字符分割、递归字符分割、标记分割等
   - 支持重叠窗口（overlap）以保持上下文连续性
   - 示例：`RecursiveCharacterTextSplitter`、`CharacterTextSplitter`、`TokenTextSplitter`

3. **嵌入模型（Embeddings）**
   - `langchain.embeddings`：将文本转换为向量表示
   - 支持多种嵌入模型：OpenAI、HuggingFace、本地模型等
   - 示例：`OpenAIEmbeddings`、`HuggingFaceEmbeddings`、`SentenceTransformerEmbeddings`

4. **向量存储（Vector Stores）**
   - `langchain.vectorstores`：存储和检索向量数据
   - 支持多种向量数据库：FAISS、Chroma、Pinecone、Weaviate、PGVector 等
   - 提供统一的接口：`add_documents()`、`similarity_search()`、`similarity_search_with_score()`
   - 示例：`FAISS`、`Chroma`、`PGVector`、`Pinecone`

5. **检索器（Retrievers）**
   - `langchain.retrievers`：封装检索逻辑
   - 支持多种检索策略：相似度检索、MMR（最大边际相关性）、时间加权等
   - 支持元数据过滤、多向量检索等高级功能
   - 示例：`VectorStoreRetriever`、`ContextualCompressionRetriever`、`TimeWeightedVectorStoreRetriever`

6. **链（Chains）**
   - `langchain.chains`：将多个组件组合成完整流程
   - `RetrievalQA`：经典的 RAG 链，结合检索和生成
   - `ConversationalRetrievalChain`：支持对话历史的 RAG
   - `RetrievalQAWithSourcesChain`：带来源信息的 RAG

#### 1.2.2 实现方式

LangChain 提供了多种 RAG 实现方式，适用于不同场景：

**方式一：基础 RAG 链（RetrievalQA）**

```python
from langchain.chains import RetrievalQA
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.llms import OpenAI

# 1. 创建向量存储
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(documents, embeddings)

# 2. 创建检索器
retriever = vectorstore.as_retriever()

# 3. 创建 RAG 链
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

# 4. 查询
result = qa_chain.run("用户查询")
```

**方式二：对话式 RAG（ConversationalRetrievalChain）**

```python
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

# 支持对话历史的 RAG
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

qa_chain = ConversationalRetrievalChain.from_llm(
    llm=OpenAI(),
    retriever=retriever,
    memory=memory
)
```

**方式三：自定义 RAG 流程（使用 LCEL）**

```python
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import ChatPromptTemplate

# 使用 LangChain Expression Language (LCEL) 构建自定义流程
retrieval_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | ChatPromptTemplate.from_template(template)
    | llm
    | StrOutputParser()
)
```

**方式四：作为工具集成到 Agent**

```python
from langchain.agents import create_react_agent
from langchain.tools.retriever import create_retriever_tool

# 将 RAG 检索器封装为工具
retriever_tool = create_retriever_tool(
    retriever,
    "knowledge_base_search",
    "搜索知识库以获取相关信息"
)

# 将工具添加到 Agent
agent = create_react_agent(
    llm=llm,
    tools=[retriever_tool, other_tools],
    prompt=prompt
)
```

#### 1.2.3 PGVector 支持

LangChain 提供了对 PostgreSQL + pgvector 的原生支持：

```python
from langchain.vectorstores import PGVector
from langchain.embeddings import OpenAIEmbeddings

# 创建 PGVector 向量存储
vectorstore = PGVector.from_documents(
    documents=documents,
    embedding=OpenAIEmbeddings(),
    connection_string="postgresql://user:password@localhost/dbname",
    collection_name="knowledge_base"
)

# 检索
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
```

#### 1.2.4 高级特性

1. **多向量检索**：支持为同一文档生成多个向量（不同粒度）
2. **元数据过滤**：支持基于元数据的精确过滤
3. **重排序（Re-ranking）**：使用专门的模型对检索结果重新排序
4. **上下文压缩**：压缩检索到的文档以减少 token 消耗
5. **父文档检索**：检索小块，返回父文档以保持上下文

### 1.3 LangChain RAG 的优势

1. **模块化设计**：各组件独立，易于替换和扩展
2. **丰富的集成**：支持多种向量数据库和嵌入模型
3. **统一的接口**：不同组件使用统一的接口，降低学习成本
4. **活跃的社区**：持续更新，丰富的文档和示例
5. **与 LangGraph 集成**：可以无缝集成到 LangGraph 工作流中

---

## 二、当前项目框架升级评估

### 2.1 当前项目架构分析

#### 2.1.1 技术栈现状

**已使用的技术：**
- **LangGraph 0.2+**：用于构建多智能体路由系统
- **LangChain 0.3+**：用于 LLM 调用和工具支持
- **FastAPI**：Web 框架
- **PostgreSQL**：数据库（已支持 pgvector 扩展安装，但未实际使用）
- **Langfuse**：可观测性平台

**架构特点：**
- 采用分层架构：应用层（app/）、领域层（domain/）、基础设施层（infrastructure/）
- 使用工厂模式创建智能体（AgentFactory）
- 使用注册表模式管理工具（TOOL_REGISTRY）
- 使用 `create_react_agent` 创建 ReAct 智能体
- 支持工具动态注册和 Agent 热更新

#### 2.1.2 代码结构扫描

**当前目录结构：**

```
infrastructure/
├── database/          # 数据库层
│   ├── models/       # ORM 模型（用户、血压、预约等）
│   └── repository/   # 仓储模式
├── llm/              # LLM 客户端封装
├── observability/    # 可观测性（Langfuse、日志）
└── prompts/          # 提示词管理

domain/
├── router/           # 路由系统
├── agents/           # 智能体工厂和注册表
└── tools/            # 业务工具（血压、预约、健康事件等）
```

**关键发现：**

1. **缺少 RAG 基础设施**
   - ❌ 没有 `infrastructure/rag/` 目录
   - ❌ 没有向量存储实现
   - ❌ 没有嵌入服务实现
   - ❌ 没有文档加载和预处理模块

2. **数据库模型未包含向量存储**
   - ✅ 已有业务数据模型（用户、血压、预约等）
   - ❌ 没有知识库文档模型
   - ❌ 没有向量存储表结构

3. **工具系统未包含 RAG 工具**
   - ✅ 已有业务工具（血压、预约等）
   - ✅ 工具注册表支持动态注册
   - ❌ 没有 RAG 检索工具

4. **Agent 系统支持工具集成**
   - ✅ 使用 `create_react_agent`，支持工具动态添加
   - ✅ 工具通过配置文件动态加载
   - ✅ 可以轻松添加 RAG 工具

5. **配置系统**
   - ✅ 使用 YAML 配置文件管理 Agent
   - ✅ 支持环境变量配置
   - ❌ 缺少 RAG 相关配置项

### 2.2 需要改造的内容

#### 2.2.1 基础设施层改造

**需要新增的模块：**

1. **`infrastructure/rag/` 目录结构**
   ```
   infrastructure/rag/
   ├── __init__.py
   ├── embeddings.py          # 嵌入服务封装
   ├── vector_store.py        # 向量存储接口和实现
   ├── document_loader.py     # 文档加载器
   ├── text_splitter.py       # 文本拆分器
   └── retriever.py           # RAG 检索器封装
   ```

2. **数据库模型扩展**
   - 在 `infrastructure/database/models/` 中新增：
     - `rag_document.py`：知识库文档模型
     - `rag_chunk.py`：文档分块模型（可选，如果使用关系型数据库存储）

3. **数据库迁移**
   - 使用 Alembic 创建向量存储表
   - 确保 pgvector 扩展已安装

#### 2.2.2 领域层改造

**需要新增的模块：**

1. **RAG 工具**
   - 在 `domain/tools/` 中新增：
     - `rag/` 目录
     - `rag/retrieve.py`：RAG 检索工具
     - 在 `domain/tools/registry.py` 中注册 RAG 工具

2. **Agent 配置扩展**
   - 在 `config/agents.yaml` 中为需要的 Agent 添加 RAG 工具
   - 示例：
     ```yaml
     blood_pressure_agent:
       tools:
         - record_blood_pressure
         - query_blood_pressure
         - update_blood_pressure
         - retrieve_knowledge_base  # 新增 RAG 工具
     ```

#### 2.2.3 配置系统改造

**需要新增的配置项：**

在 `app/core/config.py` 中添加：

```python
# RAG 配置
RAG_ENABLED: bool = True
RAG_EMBEDDING_MODEL: str = "text-embedding-ada-002"  # 或本地模型
RAG_EMBEDDING_DIMENSION: int = 1536
RAG_VECTOR_STORE_TYPE: str = "pgvector"  # pgvector, faiss, chroma
RAG_COLLECTION_NAME: str = "knowledge_base"
RAG_TOP_K: int = 5  # 检索返回的文档数量
RAG_SIMILARITY_THRESHOLD: float = 0.7  # 相似度阈值
```

#### 2.2.4 依赖管理改造

**需要新增的依赖：**

在 `requirements.txt` 中添加：

```txt
# RAG 相关依赖
langchain-community>=0.3.0,<1.0.0  # 文档加载器、向量存储等
pgvector>=0.2.0  # PostgreSQL 向量扩展支持
sentence-transformers>=2.2.0  # 本地嵌入模型（可选）
```

### 2.3 改造优先级评估

#### 2.3.1 高优先级（必须改造）

1. **创建 RAG 基础设施模块**
   - 优先级：🔴 高
   - 原因：RAG 功能的基础，必须首先实现
   - 工作量：中等（3-5 天）

2. **实现 PGVector 向量存储**
   - 优先级：🔴 高
   - 原因：项目已使用 PostgreSQL，pgvector 是最佳选择
   - 工作量：中等（2-3 天）

3. **创建 RAG 检索工具**
   - 优先级：🔴 高
   - 原因：需要将 RAG 集成到 Agent 工具系统中
   - 工作量：小（1-2 天）

4. **数据库模型和迁移**
   - 优先级：🔴 高
   - 原因：需要存储知识库文档和向量数据
   - 工作量：小（1 天）

#### 2.3.2 中优先级（建议改造）

1. **文档加载和预处理模块**
   - 优先级：🟡 中
   - 原因：支持知识库文档的导入和管理
   - 工作量：中等（2-3 天）

2. **配置系统扩展**
   - 优先级：🟡 中
   - 原因：支持 RAG 功能的灵活配置
   - 工作量：小（0.5 天）

3. **元数据过滤支持**
   - 优先级：🟡 中
   - 原因：提高检索精度，支持按科室、类型等过滤
   - 工作量：小（1 天）

#### 2.3.3 低优先级（可选改造）

1. **多向量检索**
   - 优先级：🟢 低
   - 原因：高级功能，初期可能不需要
   - 工作量：中等（2-3 天）

2. **重排序（Re-ranking）**
   - 优先级：🟢 低
   - 原因：优化功能，可以后续添加
   - 工作量：中等（2-3 天）

3. **上下文压缩**
   - 优先级：🟢 低
   - 原因：优化功能，可以后续添加
   - 工作量：小（1-2 天）

### 2.4 改造方案建议

#### 2.4.1 分阶段实施

**阶段一：基础 RAG 功能（MVP）**
- 实现 PGVector 向量存储
- 实现基础嵌入服务（使用 OpenAI 或本地模型）
- 创建 RAG 检索工具
- 集成到现有 Agent 中

**阶段二：知识库管理**
- 实现文档加载和预处理
- 实现知识库文档管理 API
- 支持批量导入文档

**阶段三：功能增强**
- 元数据过滤
- 重排序优化
- 上下文压缩

#### 2.4.2 技术选型建议

1. **向量存储**：优先使用 PGVector
   - 理由：项目已使用 PostgreSQL，无需引入新的数据库
   - 优势：统一的数据管理，事务支持，易于维护

2. **嵌入模型**：初期使用 OpenAI Embeddings，后续支持本地模型
   - 理由：OpenAI 嵌入质量高，易于集成
   - 后续：可以支持 HuggingFace 模型以降低成本

3. **文档加载**：使用 LangChain 的文档加载器
   - 理由：LangChain 提供了丰富的文档加载器，无需重复造轮子

4. **文本拆分**：使用 `RecursiveCharacterTextSplitter`
   - 理由：适合中文和英文混合文本，支持重叠窗口

### 2.5 兼容性评估

#### 2.5.1 与现有架构的兼容性

✅ **高度兼容：**
- Agent 系统：`create_react_agent` 天然支持工具，RAG 可以作为工具无缝集成
- 工具注册表：现有的工具注册机制可以直接使用
- 配置系统：YAML 配置可以轻松扩展

✅ **中等兼容：**
- 数据库：需要新增表和扩展，但不影响现有业务表
- 提示词系统：需要在提示词中引导 Agent 使用 RAG 工具

❌ **需要注意：**
- 向量存储需要额外的存储空间
- 嵌入计算需要额外的计算资源（如果使用本地模型）
- 检索可能增加响应延迟

#### 2.5.2 升级风险

1. **低风险：**
   - RAG 作为新增功能，不影响现有业务逻辑
   - 可以逐步集成，先在一个 Agent 中试点

2. **中风险：**
   - 数据库扩展（pgvector）需要数据库管理员权限
   - 向量存储表可能占用较大存储空间

3. **可控风险：**
   - 通过配置开关控制 RAG 功能的启用/禁用
   - 通过相似度阈值控制检索质量

### 2.6 总结

#### 2.6.1 是否需要升级框架

**结论：不需要大规模升级框架，只需要扩展功能模块。**

**理由：**
1. ✅ 现有架构设计良好，支持模块化扩展
2. ✅ LangChain 和 LangGraph 已提供完整的 RAG 支持
3. ✅ 工具系统和 Agent 系统可以无缝集成 RAG
4. ✅ 数据库已支持 pgvector 扩展

#### 2.6.2 改造建议

1. **最小化改造**：只添加必要的 RAG 模块，不修改现有代码
2. **渐进式集成**：先在单个 Agent 中试点，验证效果后再推广
3. **配置驱动**：通过配置控制 RAG 功能的启用和参数
4. **保持兼容**：确保 RAG 功能可选，不影响现有功能

#### 2.6.3 下一步行动

1. 创建 RAG 基础设施模块（`infrastructure/rag/`）
2. 实现 PGVector 向量存储
3. 创建 RAG 检索工具
4. 编写数据库迁移脚本
5. 在配置文件中添加 RAG 相关配置
6. 选择一个 Agent 进行试点集成

---

## 三、参考资料

1. [LangChain RAG 官方文档](https://python.langchain.com/docs/use_cases/question_answering/)
2. [LangChain Vector Stores](https://python.langchain.com/docs/integrations/vectorstores/)
3. [PGVector 扩展文档](https://github.com/pgvector/pgvector)
4. [LangChain PGVector 集成](https://python.langchain.com/docs/integrations/vectorstores/pgvector)

