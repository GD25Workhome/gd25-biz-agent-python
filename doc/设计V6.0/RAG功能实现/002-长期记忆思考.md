# 002-长期记忆思考

## 一、当前系统长期记忆实现现状

### 1.1 实现现状分析

#### 1.1.1 基础设施已就绪

当前系统已经完成了长期记忆（Store）的基础设施搭建：

**初始化阶段（`app/main.py`）**：

```109:111:app/main.py
        # 初始化 Store（长期记忆）
        store = AsyncPostgresStore(checkpointer_pool)
        await store.setup()
```

**关键发现**：
- ✅ Store 已成功初始化：使用 `AsyncPostgresStore`，基于 PostgreSQL 数据库
- ✅ Store 已传入路由图：在 `create_router_graph` 中传入并绑定到编译后的图上
- ✅ 数据库表结构已创建：通过 `store.setup()` 自动创建了必要的数据库表

**数据库表结构**（从 Alembic 迁移文件可见）：
- `store` 表：存储长期记忆数据
  - `prefix`：命名空间前缀（用于隔离不同的记忆类型）
  - `key`：键值
  - `value`：存储的值（JSONB 格式）
  - `created_at`：创建时间（自动设置）
  - `updated_at`：更新时间（自动设置）
  - `expires_at`：过期时间（可选）
  - `ttl_minutes`：生存时间（分钟，可选）
  - 主键：`(prefix, key)`
  - 索引：`store_prefix_idx`（前缀索引）、`idx_store_expires_at`（过期时间索引）
- `store_migrations` 表：存储迁移版本信息

#### 1.1.2 实际使用情况

**关键发现：Store 基础设施已就绪，但尚未在业务代码中实际使用**

通过代码搜索发现：
- ❌ 没有找到任何 `store.aput()` 调用（写入长期记忆）
- ❌ 没有找到任何 `store.aget()` 调用（读取长期记忆）
- ❌ 没有找到任何 `store.asearch()` 调用（搜索长期记忆）
- ✅ 只在设计文档中提到了使用方式，但实际代码中尚未实现

**结论**：
当前系统的长期记忆功能处于"基础设施已搭建，业务逻辑待实现"的状态。Store 已经作为图配置的一部分传入，可以在节点函数中通过特定方式访问，但还没有实际的读写操作。

---

## 二、系统的长期记忆应该怎么实现

### 2.1 长期记忆的核心概念

长期记忆（Long-term Memory）是指能够跨会话、跨对话持久化存储和检索的信息，与短期记忆（Short-term Memory，即 Checkpointer 保存的对话状态）形成互补：

| 特性 | 短期记忆（Checkpointer） | 长期记忆（Store） |
|------|------------------------|------------------|
| **生命周期** | 会话级别，随会话结束可能清理 | 长期持久化，跨会话保留 |
| **存储内容** | 完整的对话状态快照（消息历史、当前意图等） | 用户偏好、设置、历史摘要、关键事实 |
| **访问方式** | 自动加载（通过 thread_id） | 手动访问（通过命名空间和键） |
| **更新频率** | 每次节点执行后自动更新 | 按需更新（业务逻辑触发） |
| **使用场景** | 单次会话的上下文连续性 | 跨会话的个性化服务 |

### 2.2 长期记忆的设计原则

#### 2.2.1 信息提取与存储

长期记忆应该存储的是**经过提炼和总结的信息**，而不是原始对话的完整副本：

**应该存储的信息**：
- ✅ 用户偏好设置（如血压单位偏好、通知偏好等）
- ✅ 关键事实信息（如用户的慢性病、常用药物、过敏史等）
- ✅ 用户画像摘要（如年龄、性别、健康状况概览等）
- ✅ 行为模式（如常用的预约时间、咨询频率等）

**不应该存储的信息**：
- ❌ 完整的对话历史（这属于短期记忆，由 Checkpointer 负责）
- ❌ 临时性的会话状态（如当前填写的表单数据）
- ❌ 频繁变化的数据（如实时的血压值，应该存储在业务数据库中）

#### 2.2.2 命名空间组织

使用命名空间（namespace）对长期记忆进行层次化组织：

```python
# 命名空间结构建议
namespace_user_preferences = ("memories", user_id)  # 用户偏好
namespace_user_profile = ("profile", user_id)      # 用户画像
namespace_health_summary = ("health", user_id)     # 健康状况摘要
namespace_blood_pressure = ("blood_pressure", user_id)  # 血压相关记忆
```

**命名空间的好处**：
- 逻辑隔离：不同类型的记忆互不干扰
- 高效检索：可以按命名空间快速定位相关记忆
- 灵活管理：可以针对不同命名空间设置不同的过期策略

#### 2.2.3 数据格式设计

长期记忆的数据应该是**结构化的、易于检索的**：

```python
# 示例：用户画像摘要
user_profile = {
    "user_id": "user_123",
    "age": 45,
    "gender": "male",
    "chronic_diseases": ["hypertension"],
    "common_medications": ["amlodipine", "metoprolol"],
    "allergies": [],
    "last_updated": "2024-01-15T10:30:00Z",
    "summary": "45岁男性，患有高血压，正在服用氨氯地平和美托洛尔"
}

# 存储到 Store
namespace = ("profile", user_id)
await store.aput(namespace, "summary", user_profile)
```

### 2.3 长期记忆的实现流程

#### 2.3.1 写入流程

```python
async def update_user_memory(
    state: RouterState,
    store: BaseStore,
    memory_type: str,
    key: str,
    value: Any
):
    """
    更新用户长期记忆
    
    Args:
        state: 路由状态
        store: Store 实例
        memory_type: 记忆类型（如 "preferences", "profile", "health"）
        key: 记忆键
        value: 记忆值
    """
    user_id = state.get("user_id")
    if not user_id:
        logger.warning("无法更新长期记忆：缺少 user_id")
        return
    
    namespace = (memory_type, user_id)
    await store.aput(namespace, key, value)
    logger.info(f"已更新长期记忆: namespace={namespace}, key={key}")
```

**写入时机**：
- 用户明确设置偏好时（如"请记住我喜欢用 mmHg 单位"）
- 关键信息确认后（如用户确认自己的慢性病）
- 周期性总结更新（如每周/每月更新用户健康状况摘要）

#### 2.3.2 读取流程

```python
async def get_user_memory(
    state: RouterState,
    store: BaseStore,
    memory_type: str,
    key: str
) -> Optional[Any]:
    """
    读取用户长期记忆
    
    Args:
        state: 路由状态
        store: Store 实例
        memory_type: 记忆类型
        key: 记忆键
        
    Returns:
        记忆值，如果不存在则返回 None
    """
    user_id = state.get("user_id")
    if not user_id:
        return None
    
    namespace = (memory_type, user_id)
    try:
        value = await store.aget(namespace, key)
        return value
    except KeyError:
        return None
```

**读取时机**：
- 对话开始时：加载用户画像和偏好，作为系统上下文
- 需要个性化服务时：根据用户偏好调整回复
- 信息缺失时：从长期记忆中补充上下文信息

#### 2.3.3 搜索流程

```python
async def search_user_memories(
    state: RouterState,
    store: BaseStore,
    memory_type: str,
    query: str = ""
) -> List[Tuple[str, Any]]:
    """
    搜索用户长期记忆
    
    Args:
        state: 路由状态
        store: Store 实例
        memory_type: 记忆类型
        query: 搜索查询（可选，空字符串表示返回所有）
        
    Returns:
        匹配的键值对列表
    """
    user_id = state.get("user_id")
    if not user_id:
        return []
    
    namespace = (memory_type, user_id)
    results = await store.asearch(namespace, query)
    return results
```

### 2.4 在 LangGraph 节点中访问 Store

LangGraph 的 Store 可以通过图的配置访问，但需要在节点函数中通过特定方式获取：

**方式一：通过状态传递（推荐）**

```python
async def agent_node(state: RouterState) -> RouterState:
    """
    Agent 节点，可以从状态中获取 store
    """
    # 注意：Store 需要通过图的上下文访问
    # 实际实现中，可能需要通过其他方式传递 store 实例
    # 例如：通过依赖注入、全局变量或图的配置访问
    pass
```

**方式二：通过工厂函数捕获（当前项目使用的方式）**

```python
def create_agent_node(store: BaseStore):
    """
    工厂函数创建节点，捕获 store 实例
    """
    async def _node(state: RouterState) -> RouterState:
        # 在这里可以使用 store
        user_id = state.get("user_id")
        namespace = ("memories", user_id)
        memory = await store.aget(namespace, "preference")
        # ... 使用 memory
        return state
    
    return _node

# 在创建图时使用
workflow.add_node("agent", create_agent_node(store))
```

**方式三：通过图的运行时上下文访问（LangGraph 支持的方式）**

LangGraph 可能支持在节点中通过运行时上下文访问 Store，但需要查看最新的 LangGraph 文档确认具体 API。

---

## 三、LangChain/LangGraph 的长期记忆实现逻辑

### 3.1 LangGraph Store 的架构设计

LangGraph 的 Store 采用了**抽象接口 + 具体实现**的设计模式：

**核心接口**：`BaseStore`

```python
class BaseStore(ABC):
    """Store 的基础接口"""
    
    @abstractmethod
    async def aput(self, namespace: tuple, key: str, value: Any) -> None:
        """存储键值对"""
        pass
    
    @abstractmethod
    async def aget(self, namespace: tuple, key: str) -> Any:
        """获取值"""
        pass
    
    @abstractmethod
    async def adelete(self, namespace: tuple, key: str) -> None:
        """删除键值对"""
        pass
    
    @abstractmethod
    async def asearch(self, namespace: tuple, query: str) -> List[Tuple[str, Any]]:
        """搜索键值对"""
        pass
```

**PostgreSQL 实现**：`AsyncPostgresStore`

- 使用 PostgreSQL 作为存储后端
- 支持命名空间隔离
- 支持过期时间（TTL）
- 支持全文搜索（通过 `asearch` 方法）

### 3.2 Store 的数据库存储结构

**表结构**（基于 Alembic 迁移文件）：

```sql
CREATE TABLE store (
    prefix TEXT NOT NULL,                    -- 命名空间前缀
    key TEXT NOT NULL,                       -- 键
    value JSONB NOT NULL,                    -- 值（JSONB 格式）
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,  -- 创建时间
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,  -- 更新时间
    expires_at TIMESTAMP WITH TIME ZONE,     -- 过期时间（可选）
    ttl_minutes INTEGER,                     -- 生存时间（分钟，可选）
    PRIMARY KEY (prefix, key)
);

CREATE INDEX store_prefix_idx ON store (prefix text_pattern_ops);
CREATE INDEX idx_store_expires_at ON store (expires_at) WHERE expires_at IS NOT NULL;
```

**存储逻辑**：
- `prefix` + `key` 组成唯一标识
- `value` 使用 JSONB 类型，支持灵活的 JSON 数据
- 通过索引优化命名空间和过期时间的查询性能

### 3.3 Store 的工作流程

#### 3.3.1 初始化流程

```python
# 1. 创建数据库连接池
checkpointer_pool = AsyncConnectionPool(conninfo=db_uri)

# 2. 创建 Store 实例
store = AsyncPostgresStore(checkpointer_pool)

# 3. 初始化数据库表结构
await store.setup()  # 自动创建 store 表和索引

# 4. 绑定到图
graph = workflow.compile(store=store)
```

#### 3.3.2 写入流程

```python
# 1. 构建命名空间
namespace = ("memories", user_id)

# 2. 准备数据
value = {"preference": "mmHg", "last_updated": "2024-01-15"}

# 3. 写入 Store
await store.aput(namespace, "blood_pressure_preference", value)

# 底层执行：
# INSERT INTO store (prefix, key, value, expires_at)
# VALUES ('memories:user_123', 'blood_pressure_preference', '{"preference": "mmHg"}', NULL)
# ON CONFLICT (prefix, key) DO UPDATE SET value = EXCLUDED.value
```

#### 3.3.3 读取流程

```python
# 1. 构建命名空间
namespace = ("memories", user_id)

# 2. 读取值
value = await store.aget(namespace, "blood_pressure_preference")

# 底层执行：
# SELECT value FROM store 
# WHERE prefix = 'memories:user_123' AND key = 'blood_pressure_preference'
```

#### 3.3.4 搜索流程

```python
# 1. 构建命名空间
namespace = ("memories", user_id)

# 2. 搜索（空字符串返回所有）
results = await store.asearch(namespace, "")

# 3. 带条件搜索（如果支持）
results = await store.asearch(namespace, "blood_pressure")

# 底层执行：
# SELECT key, value FROM store 
# WHERE prefix = 'memories:user_123' 
#   AND (query = '' OR key LIKE '%blood_pressure%' OR value::text LIKE '%blood_pressure%')
```

### 3.4 Store 与 Checkpointer 的协作

Store 和 Checkpointer 在 LangGraph 中分工明确，相互协作：

**Checkpointer（短期记忆）**：
- 自动管理：图执行时自动加载和保存
- 会话级别：每个 thread_id 对应一个会话的状态快照
- 完整状态：保存整个 RouterState 的完整副本

**Store（长期记忆）**：
- 手动管理：需要显式调用 aput/aget
- 跨会话：通过 user_id 组织，跨多个会话共享
- 精选信息：只存储经过提炼的关键信息

**协作场景**：
- Agent 可以从 Checkpointer 获取当前会话的上下文
- Agent 可以从 Store 获取用户的长期偏好和历史信息
- 两者结合，提供完整的上下文支持

---

## 四、用户信息提取功能的必要性与精确性分析

### 4.1 用户信息提取功能概述

用户信息提取功能是指：**使用 LLM 对用户的历史数据（对话历史、业务数据等）进行总结和提炼，生成结构化的用户画像，作为系统上下文的一部分提供给模型**。

### 4.2 功能必要性分析

#### 4.2.1 支持观点：用户信息提取功能是有必要的

**理由一：信息压缩与聚焦**

直接推送所有原始数据会导致：
- ❌ **信息过载**：大量原始数据会占用大量 token，增加成本
- ❌ **噪音干扰**：无关信息可能干扰模型判断
- ❌ **上下文窗口限制**：可能超出模型的上下文窗口

而用户信息提取可以：
- ✅ **信息压缩**：将大量原始数据压缩为精炼的摘要
- ✅ **聚焦关键信息**：突出重要的用户特征和偏好
- ✅ **节省 token**：显著减少上下文 token 数量

**示例对比**：

```python
# 方式一：直接推送所有数据（不推荐）
raw_data = {
    "conversations": [/* 100 条对话记录 */],
    "blood_pressure_records": [/* 200 条血压记录 */],
    "appointments": [/* 50 条预约记录 */],
    "medications": [/* 30 条用药记录 */]
}
# 总 token 数：~10,000 tokens

# 方式二：LLM 总结提取（推荐）
user_profile = {
    "age": 45,
    "gender": "male",
    "chronic_diseases": ["hypertension"],
    "current_medications": ["amlodipine 5mg daily", "metoprolol 25mg daily"],
    "blood_pressure_trend": "稳定，平均 135/85 mmHg",
    "consultation_frequency": "每月 1-2 次",
    "preferences": ["使用 mmHg 单位", "偏好上午咨询"]
}
# 总 token 数：~200 tokens（压缩比 50:1）
```

**理由二：语义理解与抽象**

LLM 总结提取的优势：
- ✅ **语义理解**：LLM 能够理解数据的语义，提取隐含的信息
- ✅ **抽象概括**：能够将具体数据抽象为高层次的特征
- ✅ **关联分析**：能够发现数据之间的关联关系

**示例**：

```python
# 原始数据
blood_pressure_data = [
    {"date": "2024-01-01", "systolic": 140, "diastolic": 90},
    {"date": "2024-01-02", "systolic": 138, "diastolic": 88},
    # ... 更多记录
]

# LLM 提取的摘要
summary = "血压整体稳定，平均值 135/85 mmHg，略高于理想值（120/80），建议继续规律服药并监测"
# ↑ 不仅包含数据，还包含医学判断和建议
```

**理由三：动态更新与时效性**

用户信息提取功能可以：
- ✅ **定期更新**：定期重新总结，确保用户画像的时效性
- ✅ **增量更新**：基于新数据增量更新，而非完全重算
- ✅ **版本管理**：保留历史版本，支持回溯和对比

#### 4.2.2 反对观点：直接推送原始数据可能更精确

**理由一：信息完整性**

直接推送原始数据的优势：
- ✅ **信息完整**：不会因为总结而丢失细节信息
- ✅ **透明度高**：模型可以直接看到原始数据，判断更透明
- ✅ **避免偏差**：不会因为总结过程中的偏差而影响判断

**理由二：模型能力**

现代大语言模型（如 GPT-4）的能力：
- ✅ **强大的上下文理解能力**：能够处理大量上下文信息
- ✅ **自动信息提取**：模型自身具备从大量数据中提取关键信息的能力
- ✅ **无需预处理**：减少预处理步骤，降低系统复杂度

### 4.3 精确性对比分析

#### 4.3.1 理论分析

**假设场景**：用户询问"我的血压最近怎么样？"

**方式一：直接推送所有血压数据**

```python
# 系统上下文
context = f"""
用户的历史血压记录：
{json.dumps(all_blood_pressure_records, indent=2)}
"""

# 优势：
# - 模型可以看到所有原始数据
# - 可以进行自己的分析和判断
# - 不会因为总结而丢失信息

# 劣势：
# - 数据量大，可能超出上下文窗口
# - 模型需要自己处理大量数据，可能分散注意力
# - 成本高（token 多）
```

**方式二：LLM 总结提取用户画像**

```python
# 系统上下文
context = f"""
用户画像：
{user_profile_summary}  # LLM 生成的摘要

用户的历史血压记录（最近 10 条）：
{recent_blood_pressure_records}
"""

# 优势：
# - 信息精炼，聚焦关键点
# - 节省 token，降低成本
# - 提供高层次的趋势分析

# 劣势：
# - 可能因为总结偏差而丢失重要细节
# - 总结可能不够准确
# - 需要额外的 LLM 调用成本
```

#### 4.3.2 精确性影响因素

**因素一：总结质量**

如果总结质量高：
- ✅ 能够准确提取关键信息
- ✅ 不会丢失重要细节
- ✅ 提供有价值的洞察

如果总结质量低：
- ❌ 可能丢失重要信息
- ❌ 可能引入错误的理解
- ❌ 反而降低精确性

**因素二：数据规模**

- **数据量小**（< 100 条记录）：直接推送可能更精确，因为数据量可控
- **数据量中等**（100-1000 条记录）：总结提取可能更合适，平衡精确性和效率
- **数据量大**（> 1000 条记录）：总结提取几乎必须，否则会超出上下文窗口

**因素三：查询类型**

- **具体查询**（如"1月1日的血压是多少"）：需要原始数据，总结无法回答
- **趋势查询**（如"血压趋势如何"）：总结提取更合适，提供高层次的洞察
- **综合查询**（如"我的健康状况如何"）：总结提取 + 关键原始数据，最佳平衡

### 4.4 混合方案：最佳实践

基于以上分析，**混合方案可能是最佳选择**：

#### 4.4.1 分层信息架构

```python
# 第一层：用户画像摘要（LLM 总结，长期记忆）
user_profile = {
    "summary": "45岁男性，高血压患者，规律服药，血压稳定",
    "key_facts": ["chronic_disease: hypertension", "medications: amlodipine, metoprolol"],
    "preferences": ["unit: mmHg", "consultation_time: morning"],
    "last_updated": "2024-01-15"
}

# 第二层：近期关键数据（原始数据，短期记忆）
recent_data = {
    "blood_pressure_last_10": [...],  # 最近 10 条血压记录
    "recent_appointments": [...],     # 最近的预约
    "current_medications": [...]      # 当前用药
}

# 第三层：完整历史数据（按需加载）
# 只有在明确需要时才加载，如用户明确询问"所有历史记录"
```

#### 4.4.2 智能上下文构建

```python
async def build_user_context(
    user_id: str,
    query: str,
    store: BaseStore,
    db_pool: AsyncConnectionPool
) -> str:
    """
    根据查询类型智能构建用户上下文
    """
    # 1. 始终加载用户画像摘要（轻量级）
    namespace = ("profile", user_id)
    user_profile = await store.aget(namespace, "summary")
    
    # 2. 根据查询类型决定加载哪些数据
    if "最近" in query or "最近" in query:
        # 趋势类查询：加载用户画像 + 近期数据
        recent_data = await get_recent_blood_pressure(user_id, limit=10)
        context = f"{user_profile}\n\n最近的数据：{recent_data}"
    elif "所有" in query or "全部" in query:
        # 详细查询：加载完整数据（可能很大）
        all_data = await get_all_blood_pressure(user_id)
        context = f"{user_profile}\n\n完整数据：{all_data}"
    else:
        # 一般查询：只加载用户画像
        context = user_profile
    
    return context
```

#### 4.4.3 总结更新策略

```python
async def update_user_profile_summary(
    user_id: str,
    store: BaseStore,
    db_pool: AsyncConnectionPool
):
    """
    定期更新用户画像摘要
    """
    # 1. 获取原始数据
    raw_data = await get_all_user_data(user_id, db_pool)
    
    # 2. 使用 LLM 总结
    summary_prompt = f"""
    请总结以下用户数据，生成用户画像摘要：
    {json.dumps(raw_data, indent=2)}
    
    要求：
    1. 提取关键信息（年龄、性别、慢性病、用药等）
    2. 总结健康状况趋势
    3. 提取用户偏好
    4. 不超过 200 字
    """
    
    summary = await llm.ainvoke(summary_prompt)
    
    # 3. 存储到 Store
    namespace = ("profile", user_id)
    await store.aput(namespace, "summary", {
        "content": summary,
        "last_updated": datetime.now().isoformat(),
        "data_snapshot_date": datetime.now().isoformat()
    })
```

### 4.5 结论与建议

#### 4.5.1 精确性对比结论

**精确性没有绝对优劣，取决于场景**：

1. **数据量小 + 具体查询**：直接推送原始数据可能更精确
2. **数据量大 + 趋势查询**：总结提取通常更精确（因为模型能更好地聚焦关键信息）
3. **混合方案**：在大多数场景下，混合方案（用户画像摘要 + 按需加载原始数据）能够取得最佳平衡

#### 4.5.2 实施建议

**建议采用混合方案**：

1. ✅ **实施用户画像提取功能**：
   - 使用 LLM 定期总结用户数据，生成用户画像摘要
   - 存储到 Store 的 `("profile", user_id)` 命名空间

2. ✅ **智能上下文构建**：
   - 默认加载用户画像摘要（轻量级，~200 tokens）
   - 根据查询类型按需加载原始数据
   - 支持"最近 N 条"、"所有记录"等不同粒度

3. ✅ **总结质量保障**：
   - 使用高质量的提示词指导总结
   - 定期验证总结的准确性
   - 支持手动修正和补充

4. ✅ **性能优化**：
   - 用户画像摘要缓存更新（如每天更新一次）
   - 原始数据按需加载，避免不必要的 token 消耗
   - 使用异步加载，不阻塞主流程

#### 4.5.3 实施优先级

**高优先级**：
- 实现用户画像提取功能（存储到 Store）
- 在 Agent 节点中加载用户画像作为系统上下文

**中优先级**：
- 实现智能上下文构建（根据查询类型按需加载数据）
- 实现用户画像的定期更新机制

**低优先级**：
- 实现用户画像的手动修正功能
- 实现用户画像的版本管理

---

## 五、总结

### 5.1 当前状态

- ✅ **基础设施已就绪**：Store 已初始化并绑定到图上
- ❌ **业务逻辑待实现**：尚未在节点中使用 Store 进行实际读写操作

### 5.2 实现建议

1. **长期记忆设计**：
   - 使用命名空间组织不同类型的记忆
   - 存储经过提炼的精选信息，而非原始数据
   - 支持过期时间和版本管理

2. **LangGraph Store 使用**：
   - 通过工厂函数捕获 Store 实例
   - 在节点中按需读写长期记忆
   - 与 Checkpointer 协作，提供完整的上下文支持

3. **用户信息提取功能**：
   - **建议实施**：能够显著提升系统的个性化能力和响应效率
   - **采用混合方案**：用户画像摘要 + 按需加载原始数据
   - **注重质量**：确保总结的准确性和时效性

### 5.3 下一步行动

1. 在 Agent 节点中实现 Store 的读写操作
2. 实现用户画像提取功能
3. 实现智能上下文构建机制
4. 编写测试用例验证长期记忆功能

---

## 六、参考资料

1. [LangGraph Store 文档](https://langchain-ai.github.io/langgraph/how-tos/persistence-store/)
2. [LangGraph Checkpointer vs Store](https://langchain-ai.github.io/langgraph/how-tos/persistence-store/#checkpointer-vs-store)
3. [PostgreSQL Store 实现](https://github.com/langchain-ai/langgraph/blob/main/langgraph/store/postgres.py)
4. 项目内部文档：
   - `cursor_docs/学习知识/Checkpointer机制详解.md`
   - `doc/设计V1.0/langGraphFlow系统核心功能设计文档.md`

