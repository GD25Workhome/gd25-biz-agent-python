# 节点2：RAG检索节点详细设计方案

## 文档说明

本文档描述节点2（RAG检索节点）的详细设计方案，包括基础数据准备、数据导入、节点代码实现、多路召回策略等。

**文档版本**：V1.0  
**创建时间**：2025-01-16  
**对应节点**：`retrieval_node`（`config/flows/medical_agent_v5/flow.yaml`）

---

## 一、节点职责与定位

### 1.1 节点职责

节点2是**RAG检索节点**，负责：

1. **向量库检索**：基于节点1输出的 `query_text` 和 `keywords`，从向量库检索相关历史问答、科普资料、对话示例等
2. **结果整合**：将检索结果格式化，传递给节点3

**注意**：用户信息查询功能暂时不需要实现，后续可根据需求添加。

### 1.2 节点定位

节点2在流程中的位置：

```
节点1：问题加工节点
  ↓ (输出: query_text, keywords)
节点2：RAG检索节点 ← 本节点
  ↓ (输出: retrieved_examples)
节点3：核心Agent节点
```

### 1.3 实现方式

- **节点类型**：函数节点（`type: function`），非Agent节点
- **实现位置**：定制化实现，独立Python代码文件
- **设计原则**：独立实现，防止脏代码影响核心流程

---

## 二、基础数据准备

### 2.1 数据来源

参考现有的提示词文件，提取有代表性的素材：

**数据来源文件**：
- `config/flows/medical_agent_v3/prompts/` 下的所有提示词文件
- `config/flows/medical_agent_v4/prompts/` 下的所有提示词文件

**重点关注文件**：
- `50-QA_agent.md`：健康问答示例、安全边界场景
- `11-record_agent.md`：数据记录对话示例
- `12-after_record_agent.md`：记录后处理示例
- `20-query_agent.md`：数据查询对话示例
- `00-intent_recognition_agent.md`：意图识别示例（如需要）

### 2.2 数据分类标准

按照问题类型和内容性质进行分类：

1. **健康咨询类问题（QA）**
   - 健康知识问答
   - 用药咨询
   - 症状询问
   - 安全边界场景（如：血压过高、紧急情况等）

2. **数据记录类问题（Record）**
   - 血压记录示例
   - 用药记录示例
   - 症状记录示例
   - 健康事件记录示例

3. **数据查询类问题（Query）**
   - 血压查询示例
   - 用药查询示例
   - 症状查询示例
   - 健康数据统计查询示例

4. **问候类问题（Greeting）**
   - 日常问候
   - 开场白
   - 寒暄对话

### 2.3 数据质量要求

**优秀示例的标准**：
- **完整性**：包含完整的问题和回答，上下文清晰
- **准确性**：回答准确、专业，符合医学规范
- **实用性**：能够有效指导用户，解决实际问题
- **代表性**：覆盖常见场景和典型问题

**数据筛选原则**：
- 优先选择高质量、经过验证的示例
- 避免重复或相似的示例
- 确保示例的多样性和覆盖面

---

## 三、数据导入

### 3.1 源数据格式设计

#### 3.1.1 Excel格式（推荐）

**文件结构**：
- 每个类别创建一个Sheet（如：QA示例、记录示例、查询示例、问候示例）
- 每个Sheet包含以下字段：

**QA示例表（qa_examples）**：
| 字段名 | 类型 | 说明 | 必填 |
|--------|------|------|------|
| user_input | 文本 | 用户输入（问题） | 是 |
| agent_response | 文本 | Agent回复（回答） | 是 |
| tags | 文本 | 标签（用于分类），逗号分隔。可包含：问题类型（健康咨询、用药咨询、症状询问等）、关键实体（疾病、症状、药物等）、场景类型（普通咨询、安全边界场景等） | 否 |
| quality_grade | 文本 | 质量等级（优秀/良好/一般） | 否 |
| notes | 文本 | 备注（仅用于数据管理，不会导入到数据库） | 否 |

**记录示例表（record_examples）**：
| 字段名 | 类型 | 说明 | 必填 |
|--------|------|------|------|
| user_input | 文本 | 用户输入 | 是 |
| agent_response | 文本 | Agent回复 | 是 |
| tags | 文本 | 标签，逗号分隔。可包含：记录类型（blood_pressure、medication、symptom、health_event）、数据完整性（完整/部分完整/需要澄清）等 | 否 |
| quality_grade | 文本 | 质量等级（优秀/良好/一般） | 否 |
| notes | 文本 | 备注（仅用于数据管理，不会导入到数据库） | 否 |

**查询示例表（query_examples）**：
| 字段名 | 类型 | 说明 | 必填 |
|--------|------|------|------|
| user_input | 文本 | 用户输入 | 是 |
| agent_response | 文本 | Agent回复 | 是 |
| tags | 文本 | 标签，逗号分隔。可包含：查询类型（blood_pressure、medication、symptom、statistics等）、时间范围（最近一周、这个月等）等 | 否 |
| quality_grade | 文本 | 质量等级（优秀/良好/一般） | 否 |
| notes | 文本 | 备注（仅用于数据管理，不会导入到数据库） | 否 |

**问候示例表（greeting_examples）**：
| 字段名 | 类型 | 说明 | 必填 |
|--------|------|------|------|
| user_input | 文本 | 用户输入 | 是 |
| agent_response | 文本 | Agent回复 | 是 |
| tags | 文本 | 标签，逗号分隔。可包含：问候类型（开场白、日常问候、告别等）等 | 否 |
| quality_grade | 文本 | 质量等级（优秀/良好/一般） | 否 |
| notes | 文本 | 备注（仅用于数据管理，不会导入到数据库） | 否 |

#### 3.1.2 JSON格式（备选）

如果Excel格式不便于处理，也可以使用JSON格式：

```json
{
  "qa_examples": [
    {
      "user_input": "用户输入（问题）",
      "agent_response": "Agent回复（回答）",
      "tags": ["健康咨询", "高血压", "降压药", "普通咨询"],
      "quality_grade": "优秀"
    }
  ],
  "record_examples": [...],
  "query_examples": [...],
  "greeting_examples": [...]
}
```

**推荐格式**：**Excel格式**，因为：
- 便于人工编辑和审核
- 支持多Sheet分类管理
- 数据可视化更直观
- 易于版本控制和协作

### 3.2 向量库表结构设计

#### 3.2.1 QA示例表（qa_examples）

```sql
CREATE TABLE qa_examples (
    id SERIAL PRIMARY KEY,
    user_input TEXT NOT NULL,                  -- 用户输入（问题）
    agent_response TEXT NOT NULL,              -- Agent回复（回答）
    tags TEXT[],                               -- 标签数组（可包含：问题类型、实体、场景类型等）
    quality_grade VARCHAR(50),                 -- 质量等级（优秀/良好/一般）
    embedding vector(768) NOT NULL,            -- 向量（768维，使用moka-ai/m3e-base）
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- 创建向量索引（HNSW，用于快速相似度搜索）
CREATE INDEX qa_examples_embedding_idx 
ON qa_examples 
USING hnsw (embedding vector_cosine_ops);
```

**重要说明**：
- **相似度分数不在表中存储**：相似度分数是相对于查询向量的，每次查询都不同，因此应该在查询时动态计算（使用 `1 - (embedding <=> query_vector)`），而不是存储在表中
- **向量索引**：使用HNSW索引（`vector_cosine_ops`）可以快速计算向量相似度，无需预先存储分数
- **字段简化**：初期只保留核心字段，类型、实体等信息可通过tags字段存储，便于后续扩展

**向量化策略**：
- 向量化文本 = `user_input + " " + agent_response`
- 这样检索时，相似的问题和答案都能被找到

#### 3.2.2 记录示例表（record_examples）

```sql
CREATE TABLE record_examples (
    id SERIAL PRIMARY KEY,
    user_input TEXT NOT NULL,                  -- 用户输入
    agent_response TEXT NOT NULL,              -- Agent回复
    tags TEXT[],                               -- 标签数组（可包含：记录类型、数据完整性等）
    quality_grade VARCHAR(50),                 -- 质量等级（优秀/良好/一般）
    embedding vector(768) NOT NULL,           -- 向量
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX record_examples_embedding_idx 
ON record_examples 
USING hnsw (embedding vector_cosine_ops);
```

**向量化策略**：
- 向量化文本 = `user_input + " " + agent_response`

#### 3.2.3 查询示例表（query_examples）

```sql
CREATE TABLE query_examples (
    id SERIAL PRIMARY KEY,
    user_input TEXT NOT NULL,                  -- 用户输入
    agent_response TEXT NOT NULL,              -- Agent回复
    tags TEXT[],                               -- 标签数组（可包含：查询类型、时间范围等）
    quality_grade VARCHAR(50),                 -- 质量等级（优秀/良好/一般）
    embedding vector(768) NOT NULL,           -- 向量
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX query_examples_embedding_idx 
ON query_examples 
USING hnsw (embedding vector_cosine_ops);
```

**向量化策略**：
- 向量化文本 = `user_input + " " + agent_response`

#### 3.2.4 问候示例表（greeting_examples）

```sql
CREATE TABLE greeting_examples (
    id SERIAL PRIMARY KEY,
    user_input TEXT NOT NULL,                  -- 用户输入
    agent_response TEXT NOT NULL,              -- Agent回复
    tags TEXT[],                               -- 标签数组（可包含：问候类型等）
    quality_grade VARCHAR(50),                 -- 质量等级（优秀/良好/一般）
    embedding vector(768) NOT NULL,           -- 向量
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX greeting_examples_embedding_idx 
ON greeting_examples 
USING hnsw (embedding vector_cosine_ops);
```

**向量化策略**：
- 向量化文本 = `user_input + " " + agent_response`

### 3.3 数据导入代码实现

#### 3.3.1 导入流程设计

**文件位置**：`backend/rag/data_import.py`（新建文件）

**导入流程**：
1. 读取Excel文件（或JSON文件）
2. 解析数据，按Sheet/类别分类
3. 数据清洗和验证
4. 文本向量化（使用moka-ai/m3e-base模型）
5. 批量插入数据库
6. 验证导入结果

#### 3.3.2 代码结构设计

**参考现有代码**：
- `cursor_test/rag/01_insertAndQuery/step1_insert.py`：向量化示例代码
- 可以复用其向量化逻辑和数据库连接逻辑

**核心函数**：
```python
def import_from_excel(excel_path: str, db_conn) -> Dict:
    """
    从Excel文件导入数据到向量库
    
    Args:
        excel_path: Excel文件路径
        db_conn: 数据库连接对象
    
    Returns:
        Dict: 导入结果统计
    """
    # 1. 读取Excel文件
    # 2. 按Sheet解析数据
    # 3. 数据清洗和验证
    # 4. 向量化并插入数据库
    # 5. 返回统计结果
    pass

def vectorize_text(text: str, model) -> List[float]:
    """
    文本向量化（复用step1_insert.py的逻辑）
    """
    pass

def insert_qa_examples(examples: List[Dict], db_conn, model) -> int:
    """
    批量插入QA示例
    """
    pass

def insert_record_examples(examples: List[Dict], db_conn, model) -> int:
    """
    批量插入记录示例
    """
    pass

def insert_query_examples(examples: List[Dict], db_conn, model) -> int:
    """
    批量插入查询示例
    """
    pass

def insert_greeting_examples(examples: List[Dict], db_conn, model) -> int:
    """
    批量插入问候示例
    """
    pass
```

#### 3.3.3 数据解析要点

**Excel解析**：
- 使用 `pandas` 或 `openpyxl` 读取Excel文件
- 按Sheet名称分类（qa_examples、record_examples等）
- 处理空值和异常数据

**数据清洗**：
- 去除空白行和无效数据
- 验证必填字段
- 标准化文本格式（去除多余空格、换行符等）

**数据验证**：
- 检查数据完整性（必填字段是否存在：user_input、agent_response）
- 验证数据格式（如：tags是否为有效格式、quality_grade是否为有效值）
- 检查数据质量（如：质量等级是否有效：优秀/良好/一般）

### 3.4 导入执行脚本

**文件位置**：`backend/rag/scripts/import_data.py`（新建文件）

**使用方式**：
```bash
cd backend/rag/scripts
python import_data.py --excel_path 提示词案例库.xlsx
```

**脚本功能**：
- 命令行参数解析
- 数据库连接初始化
- 调用导入函数
- 输出导入统计和日志

---

## 四、RAG节点代码实现

### 4.1 实现原则

**设计原则**：
- **独立性**：独立Python代码文件，不与核心流程代码耦合
- **定制化**：针对当前需求定制实现，便于快速迭代
- **可扩展性**：预留扩展接口，便于后续优化

**代码组织**：
- **文件位置**：`backend/nodes/retrieval_node.py`（新建文件）
- **模块结构**：
  ```
  backend/nodes/
    ├── __init__.py
    └── retrieval_node.py  # 节点2实现
  ```

### 4.2 节点函数签名

**函数签名**：
```python
def retrieval_node(state: FlowState) -> FlowState:
    """
    RAG检索节点（节点2）
    
    功能：
    1. 从state中读取节点1的输出（query_text、keywords）
    2. 执行向量库检索
    3. 格式化检索结果
    4. 将结果写入state，传递给节点3
    
    Args:
        state: 流程状态对象（FlowState）
    
    Returns:
        FlowState: 更新后的状态对象
    """
    pass
```

**状态读取**：
- 从 `state.prompt_vars` 中读取节点1的输出：
  - `query_text`: 优化后的查询文本
  - `keywords`: 关键词列表

**状态写入**：
- 将结果写入 `state.prompt_vars`：
  - `retrieved_examples`: 检索到的示例列表（格式化后的）

### 4.3 向量库检索实现

#### 4.3.1 检索函数设计

**核心函数**：
```python
def vector_db_search(
    query_text: str,
    keywords: List[str] = None,
    top_k: int = 15,
    similarity_threshold: float = 0.7,
    table_names: List[str] = None
) -> List[Dict]:
    """
    向量库检索
    
    Args:
        query_text: 查询文本（来自节点1）
        keywords: 关键词列表（可选，用于增强检索）
        top_k: 返回数量（默认15）
        similarity_threshold: 相似度阈值（默认0.7）
        table_names: 要检索的表名列表（如果为None，检索所有表）
    
    Returns:
        List[Dict]: 检索结果列表，每个元素包含：
            - content: 示例内容（格式化的文本）
            - similarity: 相似度分数
            - source: 来源表名
            - metadata: 元数据（类型、标签等）
    """
    pass
```

#### 4.3.2 查询文本处理

**处理策略**：
1. **使用优化后的查询文本**：直接使用节点1输出的 `query_text`
2. **回退机制**：如果 `query_text` 为空，使用用户原始输入
3. **关键词增强**（可选）：将 `keywords` 合并到查询文本中，增强检索效果

**示例代码**：
```python
# 获取查询文本
query_text = state.get("prompt_vars", {}).get("query_text", "")
keywords = state.get("prompt_vars", {}).get("keywords", [])

# 回退到原始输入
if not query_text:
    last_message = state.get("history_messages", [])[-1]
    if isinstance(last_message, HumanMessage):
        query_text = last_message.content

# 关键词增强（可选）
if keywords:
    enhanced_query = f"{query_text} {' '.join(keywords)}"
else:
    enhanced_query = query_text
```

#### 4.3.3 向量化处理

**使用模型**：
- 模型：`moka-ai/m3e-base`
- 维度：768维
- 归一化：使用 `normalize_embeddings=True`

**向量化代码**（复用现有实现）：
```python
from sentence_transformers import SentenceTransformer

# 加载模型（缓存机制）
model = SentenceTransformer('moka-ai/m3e-base', local_files_only=True)

# 向量化
query_embedding = model.encode(enhanced_query, normalize_embeddings=True)
```

### 4.4 多路召回实现方案

#### 4.4.1 多路检索策略

**方案设计**：简单粗暴方案（初期实现）

**实现思路**：
1. **每个表都检索**：对所有向量表执行检索（qa_examples、record_examples、query_examples、greeting_examples）
2. **合并结果**：将所有表的检索结果合并到一个列表
3. **统一排序**：按相似度分数降序排列
4. **Top-K筛选**：取前Top-K个结果（默认15个）

**理由**：
- 初期数据量较小，多表检索性能可接受
- 简单实现，易于调试和维护
- 后续可根据检索效果优化（如：根据意图类型选择特定表）

#### 4.4.2 SQL查询实现

**向量相似度查询**（使用pgvector的余弦相似度）：
```sql
-- 示例：QA示例表检索
SELECT 
    id,
    user_input,
    agent_response,
    tags,
    quality_grade,
    1 - (embedding <=> %s::vector) AS similarity_score,
    'qa_examples' AS source
FROM qa_examples
WHERE 1 - (embedding <=> %s::vector) >= %s
ORDER BY embedding <=> %s::vector
LIMIT %s;
```

**说明**：
- `<=>` 是pgvector的余弦距离操作符
- `1 - distance` 得到相似度分数（0-1之间）
- 使用 `WHERE` 过滤低于阈值的结果
- 使用 `ORDER BY` 按距离排序，取Top-K

#### 4.4.3 合并与排序实现

**代码实现**：
```python
def multi_table_search(
    query_embedding: np.ndarray,
    table_names: List[str],
    top_k_per_table: int = 5,
    similarity_threshold: float = 0.7
) -> List[Dict]:
    """
    多表检索，合并结果
    
    Args:
        query_embedding: 查询向量
        table_names: 表名列表
        top_k_per_table: 每个表检索的数量
        similarity_threshold: 相似度阈值
    
    Returns:
        List[Dict]: 合并后的检索结果，按相似度排序
    """
    all_results = []
    
    # 对每个表执行检索
    for table_name in table_names:
        results = search_in_table(
            table_name=table_name,
            query_embedding=query_embedding,
            top_k=top_k_per_table,
            threshold=similarity_threshold
        )
        all_results.extend(results)
    
    # 按相似度排序
    all_results.sort(key=lambda x: x['similarity'], reverse=True)
    
    # 取前Top-K（如果指定了全局Top-K）
    # 这里可以设置全局Top-K，比如15
    return all_results[:15]
```

**注意事项**：
- 每个表检索的数量（`top_k_per_table`）可以根据实际情况调整
- 如果某些表的数据较少，可以增加该表的检索数量
- 合并后的结果统一排序，确保质量最优的示例被优先使用

#### 4.4.4 相似度阈值处理

**阈值策略**：
- **初始阈值**：0.7（建议值，可根据实际效果调整）
- **降级策略**：如果检索结果不足（如少于5个），可以降低阈值重试
- **最小阈值**：0.5（避免返回完全不相关的结果）

**实现代码**：
```python
def search_with_fallback(
    query_embedding: np.ndarray,
    table_names: List[str],
    min_results: int = 5
) -> List[Dict]:
    """
    带降级的检索
    """
    thresholds = [0.7, 0.6, 0.5]  # 降级阈值列表
    
    for threshold in thresholds:
        results = multi_table_search(
            query_embedding=query_embedding,
            table_names=table_names,
            similarity_threshold=threshold
        )
        
        if len(results) >= min_results:
            return results
    
    # 如果所有阈值都不满足，返回空列表或降低数量要求
    return results[:min_results] if results else []
```

### 4.5 结果格式化

#### 4.5.1 检索结果格式化

**格式化函数**：
```python
def format_retrieved_examples(results: List[Dict]) -> List[Dict]:
    """
    格式化检索结果，生成节点3可用的示例文本
    
    Args:
        results: 检索结果列表
    
    Returns:
        List[Dict]: 格式化后的示例列表，每个元素包含：
            - content: 格式化的示例文本（用于注入提示词）
            - similarity: 相似度分数
            - source: 来源表名
            - metadata: 元数据
    """
    formatted = []
    
    for result in results:
        # 根据来源表名，格式化内容（统一使用user_input和agent_response）
        if result['source'] in ['qa_examples', 'record_examples', 'query_examples', 'greeting_examples']:
            content = f"用户：{result['user_input']}\n助手：{result['agent_response']}"
        else:
            content = str(result)  # 默认格式
        
        formatted.append({
            'content': content,
            'similarity': result['similarity'],
            'source': result['source'],
            'metadata': result.get('metadata', {})
        })
    
    return formatted
```

### 4.6 完整节点实现

**完整代码结构**：
```python
"""
节点2：RAG检索节点实现
"""
import logging
from typing import Dict, List, Any
from langchain_core.messages import HumanMessage
from backend.domain.state import FlowState

logger = logging.getLogger(__name__)

def retrieval_node(state: FlowState) -> FlowState:
    """
    RAG检索节点（节点2）
    """
    try:
        # 1. 获取节点1的输出
        prompt_vars = state.get("prompt_vars", {})
        query_text = prompt_vars.get("query_text", "")
        keywords = prompt_vars.get("keywords", [])
        
        # 2. 回退到原始输入（如果query_text为空）
        if not query_text:
            history_messages = state.get("history_messages", [])
            if history_messages:
                last_message = history_messages[-1]
                if isinstance(last_message, HumanMessage):
                    query_text = last_message.content
        
        # 3. 向量库检索
        retrieved_examples = vector_db_search(
            query_text=query_text,
            keywords=keywords,
            top_k=15,
            similarity_threshold=0.7
        )
        
        # 4. 格式化结果
        formatted_examples = format_retrieved_examples(retrieved_examples)
        
        # 5. 更新状态
        if "prompt_vars" not in state:
            state["prompt_vars"] = {}
        
        state["prompt_vars"]["retrieved_examples"] = formatted_examples
        
        logger.info(f"检索到 {len(formatted_examples)} 个示例")
        
        return state
        
    except Exception as e:
        logger.error(f"RAG检索节点执行失败: {e}", exc_info=True)
        # 降级：返回空结果
        if "prompt_vars" not in state:
            state["prompt_vars"] = {}
        state["prompt_vars"]["retrieved_examples"] = []
        return state
```

### 4.7 节点注册与集成

#### 4.8.1 节点注册

在GraphBuilder中注册节点2：

**文件位置**：需要找到或创建GraphBuilder代码

**注册代码**（示例）：
```python
from backend.nodes.retrieval_node import retrieval_node

# 在GraphBuilder中
graph.add_node("retrieval_node", retrieval_node)
```

#### 4.8.2 代码可行性评估

**可行性分析**：

✅ **状态读写**：
- LangGraph支持在节点函数中读写状态
- `FlowState` 使用 `TypedDict`，支持动态字段
- 可以从 `state.prompt_vars` 读取节点1的输出
- 可以向 `state.prompt_vars` 写入节点2的输出

✅ **函数节点支持**：
- LangGraph支持函数节点（`type: function`）
- 函数节点只需要接收 `state` 并返回 `state`
- 与Agent节点（`type: agent`）的实现方式不同，但都通过 `add_node` 注册

✅ **向量库集成**：
- 已有向量化示例代码（`step1_insert.py`）
- 可以复用数据库连接和向量化逻辑
- pgvector支持向量相似度查询

⚠️ **注意事项**：
- 需要确认 `FlowState` 的定义是否支持 `prompt_vars` 字段
- 如果 `FlowState` 定义过于严格，可能需要扩展或调整
- 需要确认GraphBuilder如何识别 `type: function` 的节点并注册

**建议**：
- 先实现节点函数的基本逻辑
- 在GraphBuilder中添加函数节点的注册逻辑
- 如果遇到类型检查问题，可以使用 `total=False` 的 `TypedDict` 或动态字段

---

## 五、多路召回实现方案详解

### 5.1 方案选择

**当前方案**：简单粗暴方案（多表检索 + 合并排序）

**方案特点**：
- ✅ 实现简单，易于调试
- ✅ 初期数据量小，性能可接受
- ✅ 能够充分利用所有数据源
- ⚠️ 如果数据量大，可能有性能问题
- ⚠️ 没有根据意图类型选择特定表，可能检索到不相关的结果

**备选方案**（未来优化）：
- **基于意图的检索**：根据节点1或节点3的意图判断，选择特定表检索
- **混合检索**：向量检索 + 关键词检索（BM25）
- **重排序机制**：使用更复杂的排序算法（如：考虑时间权重、质量权重等）

### 5.2 多表检索实现细节

#### 5.2.1 检索表选择

**表列表**：
```python
DEFAULT_TABLE_NAMES = [
    'qa_examples',          # 健康问答示例
    'record_examples',      # 记录示例
    'query_examples',       # 查询示例
    'greeting_examples'     # 问候示例
]
```

**可配置性**：
- 可以在配置文件中指定要检索的表
- 可以根据问题类型动态选择表（未来优化）

#### 5.2.2 每个表的检索数量

**策略**：
- **初始设置**：每个表检索5个结果（`top_k_per_table=5`）
- **合并后筛选**：从所有结果中取前15个（`global_top_k=15`）
- **理由**：确保每个表都有机会被检索到，同时控制总结果数量

**配置参数**：
```python
RETRIEVAL_CONFIG = {
    'top_k_per_table': 5,        # 每个表检索的数量
    'global_top_k': 15,          # 最终返回的数量
    'similarity_threshold': 0.7,  # 相似度阈值
}
```

#### 5.2.3 合并与排序策略

**合并规则**：
1. **跨表合并**：将所有表的检索结果合并到一个列表
2. **去重处理**（可选）：如果发现重复内容，可以去除
3. **统一排序**：按相似度分数降序排列
4. **Top-K筛选**：取前Top-K个结果

**排序依据**：
- **主要依据**：相似度分数（降序）
- **次要依据**（可选）：质量等级、时间权重等

**实现代码**：
```python
def merge_and_rank_results(
    all_results: List[Dict],
    global_top_k: int = 15
) -> List[Dict]:
    """
    合并并排序检索结果
    """
    # 按相似度排序
    sorted_results = sorted(
        all_results,
        key=lambda x: x['similarity'],
        reverse=True
    )
    
    # 可选：去重（基于内容相似度）
    # deduplicated = deduplicate_by_content(sorted_results)
    
    # 取Top-K
    return sorted_results[:global_top_k]
```

### 5.3 相似度阈值策略

#### 5.3.1 阈值设置

**初始阈值**：0.7
- 经验值，确保检索到的结果与查询相关
- 可以根据实际效果调整

**阈值调整原则**：
- 如果检索结果太少（<5个），降低阈值
- 如果检索结果质量差，提高阈值
- 根据问题类型设置不同阈值（未来优化）

#### 5.3.2 降级策略

**降级流程**：
1. 首先使用阈值0.7检索
2. 如果结果数量 < 5，降低到0.6重试
3. 如果结果数量仍然 < 5，降低到0.5重试
4. 如果结果数量仍然不足，返回已有结果（即使少于5个）

**实现代码**（见4.4.4节）

### 5.4 检索结果质量保证

#### 5.4.1 结果验证

**验证内容**：
- 相似度分数是否在合理范围（0-1）
- 示例内容是否完整（不为空）
- 元数据是否完整

#### 5.4.2 质量过滤

**质量过滤规则**（可选）：
- 优先选择质量等级为"优秀"的示例
- 过滤掉质量等级为"一般"的示例（如果结果充足）
- 考虑时间因素（较新的示例优先，如果相似度接近）

**实现代码**（可选）：
```python
def quality_filter(results: List[Dict]) -> List[Dict]:
    """
    根据质量等级过滤结果
    """
    # 优先保留质量等级高的示例
    quality_scores = {
        '优秀': 3,
        '良好': 2,
        '一般': 1
    }
    
    # 如果结果充足（>15），过滤掉质量等级低的
    if len(results) > 15:
        filtered = [
            r for r in results
            if quality_scores.get(r.get('quality_grade', '一般'), 1) >= 2
        ]
        return filtered if filtered else results
    
    return results
```

---

## 六、数据传递约定

### 6.1 节点间数据传递

**传递路径**：
```
节点1 (prompt_vars) → 节点2 (读取) → 节点2 (prompt_vars) → 节点3 (读取)
```

**数据存储位置**：
- 统一使用 `state.prompt_vars` 字典存储
- 避免污染 `state` 的其他字段
- 便于后续扩展和调整

### 6.2 节点1输出（输入给节点2）

**字段定义**：
```python
state.prompt_vars = {
    "query_text": str,        # 优化后的查询文本
    "keywords": List[str]     # 关键词列表
}
```

**字段说明**：
- `query_text`：字符串，优化后的问题，用于向量库检索
- `keywords`：字符串列表，提取的关键实体

### 6.3 节点2输出（输入给节点3）

**字段定义**：
```python
state.prompt_vars = {
    # ... 节点1的输出（保持不变）
    "query_text": str,
    "keywords": List[str],
    
    # 节点2新增的输出
    "retrieved_examples": List[Dict]   # 检索到的示例列表（格式化后的）
}
```

**字段详细说明**：

**retrieved_examples**（列表，每个元素是字典）：
```python
{
    "content": str,          # 格式化的示例文本（用于注入提示词）
    "similarity": float,     # 相似度分数（0-1）
    "source": str,           # 来源表名（qa_examples/record_examples等）
    "metadata": Dict         # 元数据（类型、标签等）
}
```

### 6.4 节点3使用方式

**节点3提示词注入**：
- 节点3的提示词模板中包含占位符：`{retrieved_examples}`
- 在构建提示词时，从 `state.prompt_vars` 读取数据
- 格式化后替换占位符

**格式化函数**（在GraphBuilder或节点3中实现）：
```python
def format_for_prompt(prompt_vars: Dict) -> Dict[str, str]:
    """
    格式化prompt_vars中的数据，生成提示词文本
    """
    # 格式化检索示例
    examples_text = format_examples_list(
        prompt_vars.get("retrieved_examples", [])
    )
    
    return {
        "retrieved_examples": examples_text
    }
```

### 6.5 数据格式调整说明

**设计考虑**：
- 当前设计是初步方案，后续可能需要根据实际使用情况调整
- 如果发现字段不合理，可以随时修改
- 建议在节点3的提示词中做好兼容处理（能够处理字段缺失的情况）

**兼容性建议**：
- 节点3的提示词应该能够处理 `retrieved_examples` 为空列表的情况
- 提供默认值或降级方案（如果没有检索到示例，使用通用规则回答）

---

## 七、错误处理与降级策略

### 7.1 向量库检索失败

**失败场景**：
- 数据库连接失败
- 向量库表不存在
- SQL查询错误
- 向量化模型加载失败

**降级策略**：
```python
try:
    retrieved_examples = vector_db_search(...)
except Exception as e:
    logger.error(f"向量库检索失败: {e}")
    retrieved_examples = []  # 降级：返回空列表
```

**节点3处理**：
- 提示词中说明：如果没有检索到示例，使用通用规则回答
- 不阻塞流程执行

### 7.2 查询文本为空

**场景**：
- 节点1没有输出 `query_text`
- `query_text` 为空字符串

**处理策略**：
```python
query_text = prompt_vars.get("query_text", "")
if not query_text:
    # 回退到用户原始输入
    last_message = state.get("history_messages", [])[-1]
    if isinstance(last_message, HumanMessage):
        query_text = last_message.content
```

### 7.4 检索结果不足

**场景**：
- 相似度阈值过高，检索结果 < 5个
- 向量库数据量不足

**处理策略**：
- 使用降级阈值重试（见4.4.4节）
- 如果仍然不足，返回已有结果（即使少于5个）
- 节点3应该能够处理示例数量较少的情况

---

## 八、性能优化考虑

### 8.1 向量化模型缓存

**优化点**：
- SentenceTransformer模型首次加载较慢（需要下载）
- 应该缓存模型实例，避免重复加载

**实现方式**：
```python
_model_cache = None

def get_embedding_model():
    """获取向量化模型（带缓存）"""
    global _model_cache
    if _model_cache is None:
        _model_cache = SentenceTransformer(
            'moka-ai/m3e-base',
            local_files_only=True
        )
    return _model_cache
```

### 8.2 数据库连接池

**优化点**：
- 每次检索都创建新连接，性能较差
- 应该使用连接池

**实现方式**：
- 使用项目现有的数据库连接池
- 在节点函数中复用连接

### 8.3 批量检索优化

**优化点**：
- 多表检索时，可以并行执行（如果数据库支持）

**实现方式**（未来优化）：
```python
import asyncio

async def parallel_multi_table_search(...):
    """并行多表检索"""
    tasks = [
        search_in_table_async(table_name, ...)
        for table_name in table_names
    ]
    results = await asyncio.gather(*tasks)
    return merge_results(results)
```

### 8.4 结果缓存（可选）

**优化点**：
- 如果相同查询重复出现，可以缓存结果

**实现方式**（可选，未来优化）：
- 使用Redis缓存检索结果
- 缓存key：`hash(query_text + keywords)`
- 缓存过期时间：1小时

---

## 九、测试计划

### 9.1 单元测试

**测试内容**：
1. **向量化功能测试**
   - 测试文本向量化是否正确
   - 测试向量维度是否正确（768维）

2. **检索功能测试**
   - 测试单表检索
   - 测试多表检索和合并
   - 测试相似度阈值过滤
   - 测试降级策略

3. **格式化功能测试**
   - 测试正常查询
   - 测试查询失败降级

4. **节点函数测试**
   - 测试状态读取和写入
   - 测试错误处理

**测试文件位置**：`cursor_test/nodes/test_retrieval_node.py`

### 9.2 集成测试

**测试内容**：
1. **端到端流程测试**
   - 节点1 → 节点2 → 节点3 完整流程
   - 验证数据传递是否正确

2. **检索效果测试**
   - 使用真实查询文本测试检索相关性
   - 验证检索结果是否有助于节点3回答

**测试文件位置**：`cursor_test/flows/test_rag_flow.py`

### 9.3 性能测试

**测试内容**：
- 检索响应时间（目标：< 500ms）
- 多表检索性能
- 并发查询性能

---

## 十、开发任务拆分

根据上述设计方案，将开发工作拆分为以下阶段和任务：

### 阶段一：基础数据准备

**目标**：准备向量库所需的基础数据

**任务清单**：

1. **数据源分析**
   - [ ] 分析现有提示词文件，识别所有包含示例、案例的内容
   - [ ] 统计各类别示例数量（QA、记录、查询、问候）
   - [ ] 评估数据质量和完整性

2. **Excel文档设计**
   - [ ] 设计Excel文档结构（Sheet分类、字段定义）
   - [ ] 创建Excel模板文件
   - [ ] 编写数据填写说明文档

3. **数据抽取与整理**
   - [ ] 从提示词文件中提取示例数据
   - [ ] 按照分类标准整理数据
   - [ ] 填写Excel文档
   - [ ] 数据质量审核

4. **数据验证**
   - [ ] 验证数据完整性（必填字段）
   - [ ] 验证数据格式（字段类型、值域）
   - [ ] 统计各类别数据量



**交付物**：
- Excel文档：`提示词案例库.xlsx`
- 数据统计报告

---

### 阶段二：向量库表结构创建（使用Alembic）

**目标**：使用Alembic创建向量库表结构和索引

**任务清单**：

1. **SQLAlchemy模型定义**
   - [ ] 在 `backend/infrastructure/database/models/` 中创建RAG向量表模型
   - [ ] 定义4个模型类：QAExample、RecordExample、QueryExample、GreetingExample
   - [ ] 使用 `pgvector.sqlalchemy.Vector(768)` 定义向量字段
   - [ ] 确保模型继承自 `Base`

2. **Alembic配置更新**
   - [ ] 在 `alembic/env.py` 中注册pgvector类型（避免类型识别警告）
   - [ ] 确保pgvector扩展在迁移前已安装
   - [ ] 导入新创建的RAG模型类

3. **Alembic迁移脚本生成**
   - [ ] 使用 `alembic revision --autogenerate -m "add_rag_vector_tables"` 生成迁移脚本
   - [ ] 检查生成的迁移脚本是否正确（包含pgvector扩展创建、表创建、向量索引创建）
   - [ ] 手动调整迁移脚本（如需要）：确保pgvector扩展创建在表创建之前

4. **向量索引创建**
   - [ ] 迁移脚本中应包含HNSW向量索引创建（Alembic会自动生成）
   - [ ] 验证索引创建语句是否正确：`USING hnsw (embedding vector_cosine_ops)`

5. **表结构验证**
   - [ ] 执行迁移：`alembic upgrade head`
   - [ ] 验证表结构是否正确（连接数据库查看）
   - [ ] 验证索引是否创建成功（使用 `\d table_name` 查看索引）
   - [ ] 验证pgvector扩展是否已安装

**交付物**：
- SQLAlchemy模型：`backend/infrastructure/database/models/rag_models.py`
- Alembic迁移脚本：`alembic/versions/xxxxxx_add_rag_vector_tables.py`
- 表结构文档（可选，可从模型自动生成）

**技术要点**：

1. **SQLAlchemy模型定义示例**（`backend/infrastructure/database/models/rag_models.py`）：
   ```python
   """
   RAG向量表模型
   """
   from sqlalchemy import Column, String, Text, Integer, DateTime, ARRAY
   from sqlalchemy.sql import func as sql_func
   from pgvector.sqlalchemy import Vector
   
   from backend.infrastructure.database.base import Base, TABLE_PREFIX
   
   class QAExample(Base):
       """健康咨询问答示例表"""
       
       __tablename__ = f"{TABLE_PREFIX}qa_examples"
       
       id = Column(
           Integer,
           primary_key=True,
           autoincrement=True,
           index=True,
           comment="主键ID"
       )
       user_input = Column(
           Text,
           nullable=False,
           comment="用户输入（问题）"
       )
       agent_response = Column(
           Text,
           nullable=False,
           comment="Agent回复（回答）"
       )
       tags = Column(
           ARRAY(String),
           nullable=True,
           comment="标签数组（可包含：问题类型、实体、场景类型等）"
       )
       quality_grade = Column(
           String(50),
           nullable=True,
           comment="质量等级（优秀/良好/一般）"
       )
       embedding = Column(
           Vector(768),
           nullable=False,
           comment="向量（768维，使用moka-ai/m3e-base）"
       )
       created_at = Column(
           DateTime(timezone=True),
           nullable=False,
           server_default=sql_func.now(),
           comment="创建时间（自动生成）"
       )
       updated_at = Column(
           DateTime(timezone=True),
           nullable=True,
           onupdate=sql_func.now(),
           comment="更新时间（自动更新）"
       )
   
   # 类似地定义其他3个表：RecordExample、QueryExample、GreetingExample
   ```

2. **模型注册**（更新 `backend/infrastructure/database/models/__init__.py`）：
   ```python
   from backend.infrastructure.database.models.rag_models import (
       QAExample,
       RecordExample,
       QueryExample,
       GreetingExample
   )
   
   __all__ = [
       # ... 现有模型 ...
       "QAExample",
       "RecordExample",
       "QueryExample",
       "GreetingExample",
   ]
   ```

3. **Alembic env.py配置更新**（添加pgvector类型支持）：
   ```python
   # 在 alembic/env.py 文件顶部添加导入
   try:
       import pgvector
       from pgvector.sqlalchemy import Vector
       HAS_PGVECTOR = True
   except ImportError:
       HAS_PGVECTOR = False
       Vector = None
   
   # 在 do_run_migrations() 函数中添加pgvector类型注册
   def do_run_migrations(connection):
       # 注册pgvector类型到SQLAlchemy dialect（避免类型识别警告）
       if HAS_PGVECTOR and Vector is not None:
           connection.dialect.ischema_names['vector'] = Vector
       
       context.configure(connection=connection, target_metadata=target_metadata)
       
       with context.begin_transaction():
           context.run_migrations()
   ```

4. **迁移脚本示例**（自动生成后可能需要调整）：
   ```python
   """add_rag_vector_tables
   
   Revision ID: xxxxxx
   Revises: 1fb39c2bd34d
   Create Date: 2025-01-XX XX:XX:XX
   
   """
   from typing import Sequence, Union
   from alembic import op
   import sqlalchemy as sa
   from sqlalchemy.dialects import postgresql
   
   # revision identifiers, used by Alembic.
   revision: str = 'xxxxxx'
   down_revision: Union[str, Sequence[str], None] = '1fb39c2bd34d'
   branch_labels: Union[str, Sequence[str], None] = None
   depends_on: Union[str, Sequence[str], None] = None
   
   def upgrade() -> None:
       """Upgrade schema."""
       # 确保pgvector扩展已安装
       op.execute("CREATE EXTENSION IF NOT EXISTS vector")
       
       # 创建QA示例表
       op.create_table(
           'gd2502_qa_examples',
           sa.Column('id', sa.Integer(), nullable=False, comment='主键ID'),
           sa.Column('user_input', sa.Text(), nullable=False, comment='用户输入（问题）'),
           sa.Column('agent_response', sa.Text(), nullable=False, comment='Agent回复（回答）'),
           sa.Column('tags', postgresql.ARRAY(sa.String()), nullable=True, comment='标签数组'),
           sa.Column('quality_grade', sa.String(50), nullable=True, comment='质量等级'),
           sa.Column('embedding', sa.Text(), nullable=False, comment='向量（768维）'),  # Alembic可能生成为Text，需要手动改为Vector
           sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
           sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
           sa.PrimaryKeyConstraint('id')
       )
       
       # 创建向量索引（HNSW）- 需要手动添加，Alembic可能不会自动生成
       op.execute("""
           CREATE INDEX gd2502_qa_examples_embedding_idx 
           ON gd2502_qa_examples 
           USING hnsw (embedding vector_cosine_ops)
       """)
       
       # 类似地创建其他3个表...
   
   def downgrade() -> None:
       """Downgrade schema."""
       # 删除表和索引（顺序与创建相反）
       op.drop_index('gd2502_qa_examples_embedding_idx', table_name='gd2502_qa_examples')
       op.drop_table('gd2502_qa_examples')
       # ... 删除其他表 ...
   ```

**重要注意事项**：

1. **pgvector包安装**：
   ```bash
   pip install pgvector
   ```
   确保项目中已安装 `pgvector` 包（用于SQLAlchemy集成）

2. **迁移脚本调整**：
   - Alembic 自动生成的迁移脚本可能将 `Vector` 类型识别为 `Text`，需要手动调整为 `Vector(768)`
   - 向量索引（HNSW）可能需要手动添加到迁移脚本中（Alembic可能不会自动生成）
   - 确保 `CREATE EXTENSION IF NOT EXISTS vector` 在表创建之前执行

3. **表命名规范**：
   - 遵循项目现有的命名规范：使用 `TABLE_PREFIX`（当前为 `gd2502_`）
   - 表名：`gd2502_qa_examples`、`gd2502_record_examples` 等

4. **验证步骤**：
   ```bash
   # 1. 检查模型定义是否正确
   # 2. 生成迁移脚本
   alembic revision --autogenerate -m "add_rag_vector_tables"
   
   # 3. 检查生成的迁移脚本，手动调整（如果需要）
   # 4. 执行迁移
   alembic upgrade head
   
   # 5. 验证表结构
   # 连接数据库，执行：
   # \d gd2502_qa_examples  # 查看表结构
   # \di gd2502_qa_examples_embedding_idx  # 查看索引
   ```

---

### 阶段三：数据导入功能开发

**目标**：开发从Excel导入数据到向量库的功能

**任务清单**：

1. **数据解析模块开发**
   - [ ] 实现Excel文件读取功能（使用pandas/openpyxl）
   - [ ] 实现按Sheet分类解析功能
   - [ ] 实现数据清洗和验证功能

2. **向量化模块开发**
   - [ ] 封装向量化函数（复用step1_insert.py的逻辑）
   - [ ] 实现模型缓存机制
   - [ ] 测试向量化功能

3. **数据导入模块开发**
   - [ ] 实现批量插入功能（按表分类）
   - [ ] 实现数据导入主函数
   - [ ] 添加进度显示和日志记录

4. **导入脚本开发**
   - [ ] 开发命令行导入脚本
   - [ ] 添加命令行参数解析
   - [ ] 添加错误处理和日志输出

5. **测试与验证**
   - [ ] 测试Excel文件解析
   - [ ] 测试向量化准确性
   - [ ] 测试数据导入完整性
   - [ ] 验证导入后的数据质量

**交付物**：
- 数据导入模块：`backend/rag/data_import.py`
- 导入脚本：`backend/rag/scripts/import_data.py`

---

### 阶段四：RAG节点代码实现

**目标**：实现节点2的完整功能

**任务清单**：

1. **向量库检索模块开发**
   - [ ] 实现单表检索函数
   - [ ] 实现多表检索和合并函数
   - [ ] 实现相似度阈值过滤和降级策略
   - [ ] 实现结果排序和Top-K筛选

2. **结果格式化模块开发**
   - [ ] 实现检索结果格式化函数
   - [ ] 测试格式化功能

3. **节点函数实现**
   - [ ] 实现retrieval_node函数
   - [ ] 实现状态读取和写入逻辑
   - [ ] 实现错误处理和降级策略
   - [ ] 添加日志记录

4. **节点注册与集成**
   - [ ] 在GraphBuilder中添加函数节点注册逻辑
   - [ ] 测试节点注册是否成功
   - [ ] 验证节点执行流程

5. **单元测试**
   - [ ] 编写向量库检索单元测试
   - [ ] 编写格式化功能单元测试
   - [ ] 编写节点函数单元测试

**交付物**：
- RAG节点模块：`backend/nodes/retrieval_node.py`
- 检索工具模块：`backend/rag/retrieval.py`（如需要）
- 测试文件：`cursor_test/nodes/test_retrieval_node.py`

---

### 阶段五：集成测试与优化

**目标**：完成端到端测试，优化性能

**任务清单**：

1. **端到端流程测试**
   - [ ] 测试节点1 → 节点2 → 节点3完整流程
   - [ ] 验证数据传递是否正确
   - [ ] 验证检索结果是否有效

2. **检索效果测试**
   - [ ] 使用真实查询文本测试检索相关性
   - [ ] 验证不同问题类型的检索效果
   - [ ] 评估检索结果对节点3的帮助程度

3. **性能测试与优化**
   - [ ] 测试检索响应时间
   - [ ] 优化数据库连接和查询
   - [ ] 优化向量化模型缓存
   - [ ] 测试并发性能

4. **错误处理测试**
   - [ ] 测试各种错误场景（数据库失败、向量化失败等）
   - [ ] 验证降级策略是否有效
   - [ ] 验证错误不阻塞流程

5. **文档更新**
   - [ ] 更新节点2的设计文档（如有调整）
   - [ ] 编写使用说明文档
   - [ ] 编写运维文档（数据更新、问题排查等）

**交付物**：
- 集成测试文件：`cursor_test/flows/test_rag_flow.py`
- 性能测试报告
- 使用说明文档：`cursor_docs/rag节点使用说明.md`

---

## 十一、后续优化方向

### 11.1 检索策略优化

- **基于意图的检索**：根据问题类型选择特定表检索
- **混合检索**：向量检索 + 关键词检索（BM25）
- **重排序机制**：使用更复杂的排序算法

### 11.2 数据管理优化

- **定期更新机制**：从新对话中筛选优秀示例入库
- **数据质量监控**：建立数据质量评估和监控机制
- **A/B测试**：测试不同检索策略的效果

### 11.3 性能优化

- **结果缓存**：使用Redis缓存常用查询结果
- **异步检索**：并行执行多表检索
- **向量索引优化**：调整HNSW参数，优化检索性能

---

## 十二、总结

节点2（RAG检索节点）是独立提示词聚合方案的关键组件，负责：

1. **向量库检索**：基于节点1的优化查询文本，从向量库检索相关示例
2. **结果整合**：将检索结果格式化后传递给节点3

**注意**：用户信息查询功能暂时不需要实现，后续可根据需求添加。

**核心设计特点**：
- 采用定制化实现，独立代码文件，便于快速迭代
- 多路召回策略（多表检索 + 合并排序），充分利用数据源
- 完善的错误处理和降级策略，确保流程不阻塞
- 可扩展的设计，便于后续优化

**开发建议**：
- 按照阶段逐步开发，确保每个阶段都有可交付物
- 重视测试，确保功能正确性和稳定性
- 关注性能，初期可以简单实现，后续逐步优化
- 保持代码独立性，避免影响核心流程

---

**文档版本**：V1.0  
**创建时间**：2025-01-16  
**最后更新**：2025-01-16
