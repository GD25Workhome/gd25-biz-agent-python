# LangGraph流程节点集成RAG实现方案

## 文档说明

本文档描述在 LangGraph 流程中集成 RAG 检索节点的实现方案，用于验证前置RAG节点方案的可行性。

**文档版本**：v1.0  
**创建时间**：2025-01-XX  
**目标**：实现一个简单的3节点流程，验证RAG节点在LangGraph中的集成方式

---

## 目录

1. [需求分析](#一需求分析)
2. [架构设计](#二架构设计)
3. [分步实现方案](#三分步实现方案)
4. [技术选型](#四技术选型)
5. [代码结构](#五代码结构)
6. [测试计划](#六测试计划)

---

## 一、需求分析

### 1.1 实验目标

在 LangGraph 流程中验证 RAG 节点的集成，实现一个最简单的3节点流程：

1. **意图识别节点**：识别用户提问的意图（是否为健康咨询）
2. **RAG检索节点**：根据问题检索相关的科普资料
3. **回答组织节点**：基于检索结果组织回答内容

### 1.2 功能要求

- ✅ 实现基础的 LangGraph 流程结构
- ✅ 验证节点间状态传递机制
- ✅ 验证 RAG 检索在流程节点中的集成方式
- ✅ 验证检索结果如何传递给下游节点
- ✅ 验证完整的端到端流程执行

### 1.3 技术约束

- 使用项目现有的 LangGraph 框架
- 使用已有的 RAG 基础设施（pgvector + sentence-transformers）
- 遵循项目的代码规范和目录结构
- 代码存放在 `cursor_test/rag/02_lg_node` 目录

---

## 二、架构设计

### 2.1 流程图设计

```
┌─────────────────┐
│   用户输入       │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  意图识别节点    │
│ intent_node     │
└────────┬────────┘
         │
         │ intent == "qa"
         ▼
┌─────────────────┐
│  RAG检索节点     │
│  rag_node       │
│  ┌───────────┐  │
│  │ 向量查询   │  │
│  │ 知识库检索 │  │
│  └───────────┘  │
└────────┬────────┘
         │
         │ retrieved_knowledge
         ▼
┌─────────────────┐
│  回答组织节点    │
│ response_node   │
│  ┌───────────┐  │
│  │ 基于检索   │  │
│  │ 结果生成   │  │
│  │ 回答内容   │  │
│  └───────────┘  │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│   返回回答       │
└─────────────────┘
```

### 2.2 状态设计

```python
from typing import TypedDict, List, Optional
from langchain_core.messages import BaseMessage

class FlowState(TypedDict):
    """流程状态定义"""
    # 输入输出
    messages: List[BaseMessage]  # 对话消息列表
    user_query: str  # 用户问题
    
    # 意图识别结果
    intent: Optional[str]  # 识别的意图类型：qa, greeting, etc.
    intent_confidence: float  # 意图识别置信度
    
    # RAG检索结果
    retrieved_knowledge: Optional[List[dict]]  # 检索到的知识条目
    # 格式: [
    #   {
    #     "scene_name": "场景名称",
    #     "scene_conditions": "场景条件",
    #     "patient_example": "患者示例",
    #     "reply_template": "回复模板",
    #     "similarity": 0.85
    #   },
    #   ...
    # ]
    
    # 最终回答
    response: Optional[str]  # 组织后的回答内容
```

### 2.3 节点设计

#### 节点1：意图识别节点（intent_node）

**功能**：
- 接收用户输入
- 使用 LLM 识别用户意图
- 将意图结果写入状态

**输入**：`FlowState.messages`
**输出**：`FlowState.intent`, `FlowState.intent_confidence`

**实现要点**：
- 可以复用现有的意图识别逻辑（参考 `domain/router/tools/router_tools.py`）
- 或使用简化的提示词进行快速识别
- 主要识别是否为"qa"（健康问答）意图

#### 节点2：RAG检索节点（rag_node）

**功能**：
- 从 `FlowState.user_query` 获取用户问题
- 将问题向量化
- 在向量数据库中检索相关知识
- 将检索结果写入 `FlowState.retrieved_knowledge`

**输入**：`FlowState.user_query`, `FlowState.intent`
**输出**：`FlowState.retrieved_knowledge`

**实现要点**：
- 复用 `cursor_test/rag/01_insertAndQuery/step2_query.py` 中的检索逻辑
- 使用 moka-ai/m3e-base 模型进行向量化
- 使用 pgvector 进行相似度检索
- 返回 Top-K 个最相似的结果（K=3）
- 可选：设置相似度阈值过滤

#### 节点3：回答组织节点（response_node）

**功能**：
- 从 `FlowState.retrieved_knowledge` 获取检索结果
- 使用 LLM 基于检索结果组织回答
- 将回答写入 `FlowState.response`

**输入**：`FlowState.user_query`, `FlowState.retrieved_knowledge`
**输出**：`FlowState.response`

**实现要点**：
- 构建包含检索结果的提示词
- 要求 LLM 基于检索内容生成回答
- 回答格式：概要内容 + 参考来源说明

---

## 三、分步实现方案

### 第一步：实现科普内容检索工具（RAG检索节点）

#### 3.1.1 目标

实现一个可靠的 RAG 检索功能，能够：
- 接收用户问题
- 在向量知识库中检索相关内容
- 返回结构化的检索结果（概要 + 来源信息）

#### 3.1.2 技术选型

**方案A：使用本地向量数据库（推荐）**
- ✅ **优点**：
  - 已有基础设施（pgvector + sentence-transformers）
  - 可复用 `01_insertAndQuery` 中的代码
  - 响应速度快，无外部依赖
  - 数据可控，适合测试验证
- ⚠️ **缺点**：
  - 需要预先准备知识库数据
  - 数据更新需要手动维护

**方案B：使用网络搜索工具（备选）**
- ✅ **优点**：
  - 可以搜索实时信息
  - 内容更丰富
- ⚠️ **缺点**：
  - 需要额外的API密钥（Tavily、Serper等）
  - 响应时间较长
  - 内容质量不可控
  - 不适合本次实验的目标（验证RAG节点集成）

**推荐方案**：**方案A（本地向量数据库）**

理由：
1. 本次实验的目标是验证RAG节点在LangGraph中的集成方式，而非验证检索效果
2. 已有现成的RAG基础设施，可以直接复用
3. 可以复用 `01_insertAndQuery` 中的测试数据
4. 实现更简单，无外部依赖

#### 3.1.3 实现步骤

**步骤1：创建RAG检索工具函数**

```python
# cursor_test/rag/02_lg_node/rag_utils.py

def create_rag_retriever():
    """
    创建RAG检索器
    
    Returns:
        RAGRetriever: 检索器实例
    """
    # 1. 初始化数据库连接
    # 2. 加载embedding模型
    # 3. 封装检索逻辑
    pass

def retrieve_knowledge(query: str, top_k: int = 3, similarity_threshold: float = 0.7):
    """
    检索相关知识
    
    Args:
        query: 用户查询文本
        top_k: 返回Top-K个结果
        similarity_threshold: 相似度阈值
        
    Returns:
        List[dict]: 检索结果列表
    """
    pass
```

**步骤2：封装为可复用的检索服务**

- 封装数据库连接管理
- 封装模型加载（避免重复加载）
- 封装检索逻辑

**步骤3：测试检索功能**

- 编写独立测试脚本验证检索效果
- 确保返回格式符合预期

#### 3.1.4 输出格式

检索结果应返回以下格式：

```python
[
    {
        "scene_name": "血压达标场景",
        "scene_conditions": "90<=收缩压<=目标值 且 舒张压<=目标值",
        "patient_example": "我今天量了血压，120/80",
        "reply_template": "赞！血压已达标，继续加油保持！",
        "similarity": 0.85,
        "summary": "概要内容...",  # 可选：LLM生成的概要
        "source": "test_knowledge_base"  # 数据来源
    },
    ...
]
```

---

### 第二步：绘制流程图，对接模型串联整个流程

#### 3.2.1 目标

使用 LangGraph 构建完整的3节点流程，验证：
- 节点间的状态传递
- 条件路由机制
- RAG节点在流程中的集成
- 端到端的流程执行

#### 3.2.2 实现步骤

**步骤1：定义FlowState**

```python
# cursor_test/rag/02_lg_node/graph_state.py

from typing import TypedDict, List, Optional
from langchain_core.messages import BaseMessage

class FlowState(TypedDict):
    """流程状态定义"""
    messages: List[BaseMessage]
    user_query: str
    intent: Optional[str]
    intent_confidence: float
    retrieved_knowledge: Optional[List[dict]]
    response: Optional[str]
```

**步骤2：实现各节点函数**

```python
# cursor_test/rag/02_lg_node/nodes.py

def intent_node(state: FlowState) -> FlowState:
    """意图识别节点"""
    # 1. 提取用户查询
    # 2. 调用LLM进行意图识别
    # 3. 更新状态
    pass

def rag_node(state: FlowState) -> FlowState:
    """RAG检索节点"""
    # 1. 检查意图是否为"qa"
    # 2. 调用RAG检索工具
    # 3. 更新状态
    pass

def response_node(state: FlowState) -> FlowState:
    """回答组织节点"""
    # 1. 获取检索结果
    # 2. 使用LLM组织回答
    # 3. 更新状态
    pass
```

**步骤3：构建LangGraph流程**

```python
# cursor_test/rag/02_lg_node/graph.py

from langgraph.graph import StateGraph, END

def create_test_graph():
    """创建测试流程图"""
    # 1. 创建StateGraph
    workflow = StateGraph(FlowState)
    
    # 2. 添加节点
    workflow.add_node("intent", intent_node)
    workflow.add_node("rag", rag_node)
    workflow.add_node("response", response_node)
    
    # 3. 设置入口点
    workflow.set_entry_point("intent")
    
    # 4. 添加条件边：意图识别 -> RAG检索（仅当intent=="qa"）
    def should_retrieve(state: FlowState) -> str:
        if state.get("intent") == "qa":
            return "rag"
        else:
            return "response"  # 非qa意图直接跳过RAG，组织回答
    
    workflow.add_conditional_edges(
        "intent",
        should_retrieve,
        {
            "rag": "rag",
            "response": "response"
        }
    )
    
    # 5. 添加普通边：RAG检索 -> 回答组织
    workflow.add_edge("rag", "response")
    
    # 6. 添加结束边：回答组织 -> END
    workflow.add_edge("response", END)
    
    # 7. 编译图
    return workflow.compile()
```

**步骤4：创建测试脚本**

```python
# cursor_test/rag/02_lg_node/test_graph.py

def test_complete_flow():
    """测试完整流程"""
    # 1. 创建图
    graph = create_test_graph()
    
    # 2. 构建初始状态
    initial_state = {
        "messages": [HumanMessage(content="我量了血压120/80，正常吗？")],
        "user_query": "我量了血压120/80，正常吗？",
        "intent": None,
        "intent_confidence": 0.0,
        "retrieved_knowledge": None,
        "response": None
    }
    
    # 3. 执行流程
    result = graph.invoke(initial_state)
    
    # 4. 验证结果
    assert result["intent"] == "qa"
    assert result["retrieved_knowledge"] is not None
    assert result["response"] is not None
    
    print("✓ 流程执行成功")
    print(f"意图: {result['intent']}")
    print(f"检索到 {len(result['retrieved_knowledge'])} 条知识")
    print(f"回答: {result['response']}")
```

---

## 四、技术选型

### 4.1 核心技术栈

| 技术 | 版本 | 用途 |
|------|------|------|
| LangGraph | latest | 流程图构建和执行 |
| LangChain | latest | LLM调用和消息管理 |
| sentence-transformers | >=5.1.1 | 文本向量化 |
| pgvector | >=0.2.4 | 向量数据库 |
| psycopg | >=3.2.12 | PostgreSQL驱动 |

### 4.2 LLM配置

- **模型**：使用项目配置的LLM（DeepSeek Chat等）
- **意图识别**：temperature=0.0（确保稳定性）
- **回答组织**：temperature=0.7（保证创造性）

### 4.3 数据库配置

- **复用**：使用项目现有的数据库连接配置
- **表**：使用 `test_knowledge_base` 表（与01_insertAndQuery一致）
- **模型**：moka-ai/m3e-base（768维向量）

---

## 五、代码结构

```
cursor_test/rag/02_lg_node/
├── README.md                 # 使用说明文档
├── 实现方案.md               # 本文档
├── graph_state.py            # FlowState定义
├── nodes.py                  # 节点函数实现
│   ├── intent_node()         # 意图识别节点
│   ├── rag_node()            # RAG检索节点
│   └── response_node()       # 回答组织节点
├── graph.py                  # LangGraph流程图构建
│   └── create_test_graph()   # 创建测试图
├── rag_utils.py              # RAG检索工具
│   ├── create_rag_retriever()
│   └── retrieve_knowledge()
├── test_graph.py             # 测试脚本
│   └── test_complete_flow()  # 端到端测试
└── requirements.txt          # 依赖列表（如果需要）
```

---

## 六、测试计划

### 6.1 单元测试

#### 测试1：RAG检索工具测试
- **目标**：验证检索功能正常
- **输入**：测试查询"我量了血压120/80，正常吗？"
- **预期**：返回相似度排序的知识条目

#### 测试2：意图识别节点测试
- **目标**：验证意图识别准确
- **输入**：不同类型的用户问题
- **预期**：正确识别"qa"意图

#### 测试3：回答组织节点测试
- **目标**：验证能够基于检索结果生成回答
- **输入**：用户问题 + 检索结果
- **预期**：生成包含检索内容引用的回答

### 6.2 集成测试

#### 测试4：完整流程测试（qa意图）
- **输入**："我量了血压120/80，正常吗？"
- **预期流程**：
  1. 意图识别 → intent="qa"
  2. RAG检索 → 检索到相关知识
  3. 回答组织 → 生成回答
- **验证点**：
  - 状态正确传递
  - 检索结果不为空
  - 回答包含检索内容

#### 测试5：完整流程测试（非qa意图）
- **输入**："你好"
- **预期流程**：
  1. 意图识别 → intent="greeting"
  2. 跳过RAG检索
  3. 回答组织 → 生成回答
- **验证点**：
  - 条件路由正确
  - RAG检索被跳过
  - 仍然能生成回答

### 6.3 性能测试

- **响应时间**：端到端流程应在3秒内完成
- **检索性能**：RAG检索应在500ms内完成
- **并发测试**：支持多用户并发查询（可选）

---

## 七、后续扩展

### 7.1 功能扩展

1. **支持更多意图类型**：record、query等
2. **优化检索策略**：动态调整top_k和阈值
3. **添加检索结果排序**：根据相似度和相关性重新排序
4. **支持多轮对话**：保留对话历史上下文

### 7.2 性能优化

1. **模型缓存**：避免重复加载embedding模型
2. **连接池**：复用数据库连接
3. **异步处理**：使用异步节点提升并发性能

### 7.3 集成到主流程

完成验证后，可以将RAG节点集成到主流程：
- 参考 `doc/V7.0代码优化/V7.7RAG/RAG集成方案分析报告.md` 中的方案一
- 在 `domain/router/graph.py` 中添加RAG节点
- 在 `RouterState` 中添加 `retrieved_knowledge` 字段

---

## 八、风险与挑战

### 8.1 技术风险

1. **状态管理**：确保状态在节点间正确传递
2. **错误处理**：RAG检索失败时的降级策略
3. **性能瓶颈**：embedding模型加载和向量检索的耗时

### 8.2 解决方案

1. **状态验证**：在关键节点添加状态检查
2. **异常处理**：完善try-catch，提供默认返回值
3. **性能优化**：模型单例、连接池、缓存机制

---

## 九、时间估算

- **第一步（RAG检索工具）**：2-3小时
  - 封装检索逻辑：1小时
  - 测试验证：1-2小时

- **第二步（流程图实现）**：3-4小时
  - 节点函数实现：2小时
  - 流程图构建：1小时
  - 端到端测试：1小时

- **总计**：5-7小时

---

**文档版本**: v1.0  
**创建时间**: 2025-01-XX  
**作者**: AI Assistant
