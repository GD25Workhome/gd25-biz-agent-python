# 并行安全审核架构方案

## 一、方案对比分析

### 1.1 串行方案（当前方案）

**架构**：
```
用户请求 → 安全检查 → 输入审核 → 路由 → 智能体 → 回复评估 → 回复审核 → 返回
```

**优点**：
- ✅ 实现简单，逻辑清晰
- ✅ 安全性高，确保每个步骤都完成
- ✅ 易于调试和追踪问题
- ✅ 符合 LangGraph 的默认执行模式

**缺点**：
- ❌ 延迟累加，响应时间长
- ❌ 资源利用率低（等待时间）
- ❌ 不适合高并发场景

**适用场景**：
- 对安全性要求极高的场景
- 低并发场景
- 初期实现和验证阶段

### 1.2 并行方案（推荐）

**架构**：
```
用户请求
    ↓
    ├─→ 快速安全检查（同步，必须通过）
    │       ↓
    │   通过 → 继续
    │   失败 → 停止
    │
    └─→ 主业务流程（并行执行）
            ├─→ 路由智能体
            ├─→ 专门智能体
            └─→ 生成回复
    ↓
    ├─→ 深度安全检查（异步，并行）
    ├─→ 输入内容审核（异步，并行）
    └─→ 恶意行为检测（异步，并行）
    ↓
    等待所有并行任务完成
    ↓
    汇总结果
    ├─→ 如果安全检查失败 → 中断主流程，返回错误
    └─→ 如果安全检查通过 → 继续执行
    ↓
    智能体生成回复
    ↓
    ├─→ 回复质量评估（异步，并行）
    ├─→ 回复安全审核（异步，并行）
    └─→ 医疗建议风险评估（异步，并行）
    ↓
    等待所有并行任务完成
    ↓
    根据评估结果决定是否返回回复
```

**优点**：
- ✅ 响应速度快，减少延迟
- ✅ 资源利用率高
- ✅ 适合高并发场景
- ✅ 可以同时进行多项检查

**缺点**：
- ❌ 实现复杂度较高
- ❌ 需要处理异步结果汇总
- ❌ 如果安全检查失败，需要中断主流程

**适用场景**：
- 对响应时间要求高的场景
- 高并发场景
- 生产环境

### 1.3 混合方案（平衡方案）

**架构**：
```
用户请求
    ↓
    关键安全检查（同步，必须通过）
    ├─→ SQL注入检测
    ├─→ XSS攻击检测
    └─→ 频率限制检查
    ↓
    通过后，并行执行：
    ├─→ 主业务流程（路由 + 智能体）
    ├─→ 非关键安全检查（异步）
    └─→ 输入内容审核（异步）
    ↓
    智能体生成回复
    ↓
    并行执行：
    ├─→ 回复质量评估（异步）
    ├─→ 回复安全审核（异步）
    └─→ 医疗建议风险评估（异步）
    ↓
    根据评估结果决定是否返回
```

**优点**：
- ✅ 平衡了安全性和性能
- ✅ 关键安全检查确保安全
- ✅ 非关键检查并行执行，提高性能

**缺点**：
- ❌ 需要区分关键和非关键检查
- ❌ 实现复杂度中等

**适用场景**：
- 大多数生产环境
- 需要平衡安全性和性能的场景

### 1.4 异步后置审核方案

**架构**：
```
用户请求
    ↓
    快速安全检查（同步，必须通过）
    ↓
    主业务流程（路由 + 智能体）
    ↓
    立即返回回复给用户
    ↓
    后台异步执行：
    ├─→ 深度安全检查
    ├─→ 回复质量评估
    └─→ 回复安全审核
    ↓
    如果审核失败：
    ├─→ 记录日志
    ├─→ 发送告警
    └─→ 可能需要撤回或修正回复（如果支持）
```

**优点**：
- ✅ 响应速度最快
- ✅ 用户体验好

**缺点**：
- ❌ 安全性较低（审核在回复之后）
- ❌ 如果审核失败，难以撤回回复
- ❌ 不适合高风险场景

**适用场景**：
- 低风险场景
- 对响应时间要求极高的场景
- 可以接受事后审核的场景

## 二、主流做法分析

### 2.1 行业主流做法

根据对主流AI系统和安全系统的分析，**混合方案**是最主流的选择：

1. **OpenAI API**：使用混合方案
   - 关键安全检查（频率限制、内容过滤）在请求前同步执行
   - 内容审核在生成后异步执行
   - 如果审核失败，会标记内容但不立即阻止

2. **Google Cloud AI**：使用混合方案
   - 输入验证同步执行
   - 内容安全检测并行执行
   - 输出审核异步执行

3. **AWS Bedrock**：使用混合方案
   - 请求验证同步执行
   - 内容安全检测并行执行
   - 输出内容审核异步执行

4. **医疗AI系统**：通常使用串行或混合方案
   - 对安全性要求极高，关键检查必须同步
   - 非关键检查可以并行或异步

### 2.2 推荐方案

**对于医疗AI系统，推荐使用混合方案**：

1. **关键安全检查**：同步执行，必须通过
   - SQL注入检测
   - XSS攻击检测
   - 频率限制检查
   - 权限验证

2. **非关键安全检查**：并行执行
   - 敏感词检测（可以使用缓存）
   - 用户行为分析（可以异步）

3. **输入内容审核**：可以与主业务流程并行执行
   - 使用LLM进行内容审核（耗时较长）
   - 如果审核失败，可以中断主流程

4. **回复审核**：并行执行
   - 回复质量评估
   - 回复安全审核
   - 医疗建议风险评估

## 三、LangGraph 并行执行实现

### 3.1 LangGraph 并行节点支持

LangGraph 支持通过以下方式实现并行执行：

1. **使用 `asyncio.gather` 在节点内部并行执行**
2. **使用多个入口点（不适用于此场景）**
3. **使用条件边实现分支并行（需要特殊设计）**

### 3.2 实现方案一：节点内部并行

在节点内部使用 `asyncio.gather` 并行执行多个检查任务：

```python
"""
并行安全检查节点
在节点内部并行执行多个安全检查任务
"""
import asyncio
import logging
from typing import Dict, Any, List
from langchain_core.messages import AIMessage, HumanMessage
from domain.router import RouterState

logger = logging.getLogger(__name__)


async def parallel_security_check_node(state: RouterState) -> RouterState:
    """
    并行安全检查节点
    
    并行执行多个安全检查任务：
    1. 快速安全检查（SQL注入、XSS等）
    2. 敏感词检测
    3. 用户行为分析
    4. 输入内容审核（LLM）
    """
    messages = state.get("messages", [])
    if not messages:
        updated_state = state.copy()
        updated_state["security_check_passed"] = True
        return updated_state
    
    last_message = messages[-1]
    if not isinstance(last_message, HumanMessage):
        updated_state = state.copy()
        updated_state["security_check_passed"] = True
        return updated_state
    
    user_query = last_message.content
    user_id = state.get("user_id", "")
    
    # 定义并行任务
    async def quick_security_check():
        """快速安全检查（同步逻辑，快速返回）"""
        # SQL注入检测
        sql_patterns = [r"(\b(SELECT|INSERT|UPDATE|DELETE)\b)", r"(--|#|/\*|\*/)"]
        for pattern in sql_patterns:
            if re.search(pattern, user_query, re.IGNORECASE):
                return {"passed": False, "reason": "SQL注入检测", "risk_level": "high"}
        
        # XSS攻击检测
        xss_patterns = [r"<script[^>]*>.*?</script>", r"javascript:", r"on\w+\s*="]
        for pattern in xss_patterns:
            if re.search(pattern, user_query, re.IGNORECASE):
                return {"passed": False, "reason": "XSS攻击检测", "risk_level": "high"}
        
        return {"passed": True, "risk_level": "low"}
    
    async def sensitive_word_check():
        """敏感词检测（可以使用缓存）"""
        # 从缓存或数据库加载敏感词列表
        sensitive_words = ["敏感词1", "敏感词2"]  # 从配置加载
        
        for word in sensitive_words:
            if word in user_query:
                return {"passed": False, "reason": f"包含敏感词: {word}", "risk_level": "medium"}
        
        return {"passed": True, "risk_level": "low"}
    
    async def user_behavior_analysis():
        """用户行为分析（可以异步查询数据库）"""
        # 分析用户历史行为
        # 检查是否异常
        # 这里简化处理
        return {"passed": True, "risk_level": "low", "behavior_score": 0.9}
    
    async def input_content_review():
        """输入内容审核（使用LLM，耗时较长）"""
        try:
            from core.llm import get_llm_by_config
            from langchain_core.prompts import ChatPromptTemplate
            
            review_prompt = ChatPromptTemplate.from_messages([
                ("system", """你是一个内容审核专家，审核用户输入内容。

返回JSON格式：
{
    "passed": true/false,
    "risk_level": "low/medium/high",
    "reason": "审核理由"
}"""),
                ("human", "用户输入：{user_query}")
            ])
            
            llm = get_llm_by_config()
            chain = review_prompt | llm
            response = chain.invoke({"user_query": user_query})
            
            import json
            review_text = response.content if hasattr(response, 'content') else str(response)
            review_result = json.loads(review_text)
            
            return {
                "passed": review_result.get("passed", True),
                "risk_level": review_result.get("risk_level", "low"),
                "reason": review_result.get("reason", "")
            }
        except Exception as e:
            logger.error(f"输入内容审核失败: {str(e)}")
            return {"passed": True, "risk_level": "low"}  # 审核失败时默认通过
    
    # 并行执行所有检查任务
    try:
        results = await asyncio.gather(
            quick_security_check(),
            sensitive_word_check(),
            user_behavior_analysis(),
            input_content_review(),
            return_exceptions=True
        )
        
        # 汇总结果
        quick_check_result = results[0] if not isinstance(results[0], Exception) else {"passed": True}
        sensitive_word_result = results[1] if not isinstance(results[1], Exception) else {"passed": True}
        behavior_result = results[2] if not isinstance(results[2], Exception) else {"passed": True}
        content_review_result = results[3] if not isinstance(results[3], Exception) else {"passed": True}
        
        # 判断是否通过
        all_passed = (
            quick_check_result.get("passed", True) and
            sensitive_word_result.get("passed", True) and
            behavior_result.get("passed", True) and
            content_review_result.get("passed", True)
        )
        
        # 确定最高风险等级
        risk_levels = [
            quick_check_result.get("risk_level", "low"),
            sensitive_word_result.get("risk_level", "low"),
            behavior_result.get("risk_level", "low"),
            content_review_result.get("risk_level", "low")
        ]
        max_risk_level = max(risk_levels, key=lambda x: {"low": 0, "medium": 1, "high": 2}[x])
        
        updated_state = state.copy()
        updated_state["security_check_passed"] = all_passed
        updated_state["security_risk_level"] = max_risk_level
        
        if not all_passed:
            logger.warning(f"安全检查未通过: user_id={user_id}, risk_level={max_risk_level}")
            error_msg = AIMessage(content="您的内容未通过安全检查，请重新输入。")
            updated_state["messages"] = list(messages) + [error_msg]
        
        return updated_state
        
    except Exception as e:
        logger.error(f"并行安全检查失败: {str(e)}")
        # 失败时默认通过（避免阻塞正常流程）
        updated_state = state.copy()
        updated_state["security_check_passed"] = True
        return updated_state
```

### 3.3 实现方案二：主流程与安全检查并行

在主流程执行的同时，并行执行深度安全检查：

```python
"""
主流程与安全检查并行执行
"""
import asyncio
import logging
from domain.router import RouterState
from domain.router.node import router_node
from domain.agents import create_blood_pressure_agent_node

logger = logging.getLogger(__name__)


async def parallel_main_and_security_flow(state: RouterState) -> RouterState:
    """
    主流程与安全检查并行执行
    
    并行执行：
    1. 主业务流程（路由 + 智能体）
    2. 深度安全检查
    3. 输入内容审核
    """
    user_id = state.get("user_id", "")
    
    async def main_business_flow():
        """主业务流程"""
        # 执行路由节点
        state_after_router = router_node(state)
        
        # 根据路由结果执行智能体
        # 这里简化处理，实际需要根据路由决策执行对应的智能体
        # ...
        
        return state_after_router
    
    async def deep_security_check():
        """深度安全检查"""
        # 执行深度安全检查逻辑
        # ...
        return {"passed": True, "risk_level": "low"}
    
    async def input_content_review():
        """输入内容审核"""
        # 执行输入内容审核
        # ...
        return {"passed": True, "risk_level": "low"}
    
    # 并行执行
    try:
        main_result, security_result, review_result = await asyncio.gather(
            main_business_flow(),
            deep_security_check(),
            input_content_review(),
            return_exceptions=True
        )
        
        # 如果安全检查失败，中断主流程
        if isinstance(security_result, dict) and not security_result.get("passed", True):
            logger.warning(f"深度安全检查未通过: user_id={user_id}")
            updated_state = state.copy()
            updated_state["security_check_passed"] = False
            error_msg = AIMessage(content="安全检查未通过，请求已被拒绝。")
            updated_state["messages"] = state.get("messages", []) + [error_msg]
            return updated_state
        
        # 如果审核失败，标记但继续（根据业务需求决定）
        if isinstance(review_result, dict) and not review_result.get("passed", True):
            logger.warning(f"输入内容审核未通过: user_id={user_id}")
            # 可以选择继续或中断
        
        # 返回主流程结果
        if isinstance(main_result, RouterState):
            updated_state = main_result.copy()
            updated_state["security_check_passed"] = True
            return updated_state
        
        return state
        
    except Exception as e:
        logger.error(f"并行执行失败: {str(e)}")
        return state
```

### 3.4 实现方案三：回复审核并行执行

在智能体生成回复后，并行执行多个审核任务：

```python
"""
回复审核并行执行节点
"""
import asyncio
import logging
from typing import Dict, Any
from langchain_core.messages import AIMessage
from domain.router import RouterState

logger = logging.getLogger(__name__)


async def parallel_response_review_node(state: RouterState) -> RouterState:
    """
    回复审核并行执行节点
    
    并行执行：
    1. 回复质量评估
    2. 回复安全审核
    3. 医疗建议风险评估
    """
    messages = state.get("messages", [])
    if not messages:
        updated_state = state.copy()
        updated_state["response_review_passed"] = True
        return updated_state
    
    # 获取最后一条AI消息
    last_ai_message = None
    for msg in reversed(messages):
        if isinstance(msg, AIMessage):
            last_ai_message = msg
            break
    
    if not last_ai_message:
        updated_state = state.copy()
        updated_state["response_review_passed"] = True
        return updated_state
    
    response_content = last_ai_message.content
    user_id = state.get("user_id", "")
    
    async def response_quality_evaluation():
        """回复质量评估"""
        # 使用LLM评估回复质量
        # ...
        return {
            "passed": True,
            "overall_score": 0.85,
            "relevance_score": 0.9,
            "completeness_score": 0.8
        }
    
    async def response_security_review():
        """回复安全审核"""
        # 使用LLM审核回复安全性
        # ...
        return {
            "passed": True,
            "risk_level": "low",
            "security_issues": []
        }
    
    async def medical_advice_risk_assessment():
        """医疗建议风险评估"""
        # 使用LLM评估医疗建议风险
        # ...
        return {
            "passed": True,
            "risk_level": "low",
            "medical_advice_risk": "low"
        }
    
    # 并行执行所有审核任务
    try:
        results = await asyncio.gather(
            response_quality_evaluation(),
            response_security_review(),
            medical_advice_risk_assessment(),
            return_exceptions=True
        )
        
        quality_result = results[0] if not isinstance(results[0], Exception) else {"passed": True}
        security_result = results[1] if not isinstance(results[1], Exception) else {"passed": True}
        medical_risk_result = results[2] if not isinstance(results[2], Exception) else {"passed": True}
        
        # 汇总结果
        all_passed = (
            quality_result.get("passed", True) and
            security_result.get("passed", True) and
            medical_risk_result.get("passed", True)
        )
        
        # 确定最高风险等级
        risk_levels = [
            security_result.get("risk_level", "low"),
            medical_risk_result.get("risk_level", "low")
        ]
        max_risk_level = max(risk_levels, key=lambda x: {"low": 0, "medium": 1, "high": 2}[x])
        
        updated_state = state.copy()
        updated_state["response_review_passed"] = all_passed
        updated_state["response_evaluation_result"] = {
            "quality": quality_result,
            "security": security_result,
            "medical_risk": medical_risk_result
        }
        updated_state["security_risk_level"] = max_risk_level
        
        if not all_passed:
            logger.warning(f"回复审核未通过: user_id={user_id}, risk_level={max_risk_level}")
            # 可以选择返回安全回复或标记为需要人工审核
            if max_risk_level == "high":
                safe_response = AIMessage(
                    content="抱歉，系统检测到回复内容可能需要进一步审核。为了您的安全，请咨询专业医生获取更准确的建议。"
                )
                updated_state["messages"] = list(messages) + [safe_response]
        
        return updated_state
        
    except Exception as e:
        logger.error(f"并行回复审核失败: {str(e)}")
        updated_state = state.copy()
        updated_state["response_review_passed"] = True
        return updated_state
```

## 四、路由图修改（并行方案）

### 4.1 混合方案路由图

```python
def create_router_graph_with_parallel_security(
    checkpointer: AsyncPostgresSaver,
    pool: AsyncConnectionPool,
    store: AsyncPostgresStore = None
):
    """
    创建包含并行安全检查的路由图
    """
    from domain.security import (
        parallel_security_check_node,  # 并行安全检查节点
        parallel_response_review_node  # 并行回复审核节点
    )
    
    # 创建StateGraph
    router_graph = StateGraph(RouterState)
    
    # 添加节点
    router_graph.add_node("parallel_security_check", parallel_security_check_node)
    router_graph.add_node("router", router_node)
    router_graph.add_node("clarify_intent", clarify_intent_node)
    
    # 添加专门智能体节点（原有节点）
    # ... 原有代码 ...
    
    # 添加并行回复审核节点
    router_graph.add_node("parallel_response_review", parallel_response_review_node)
    
    # 设置入口点：从并行安全检查开始
    router_graph.set_entry_point("parallel_security_check")
    
    # 添加边：并行安全检查 -> 路由节点
    router_graph.add_edge("parallel_security_check", "router")
    
    # 添加条件边：路由节点 -> 专门智能体（原有逻辑）
    router_graph.add_conditional_edges(
        "router",
        route_decision,
        {
            "blood_pressure": "blood_pressure_agent",
            "appointment": "appointment_agent",
            # ... 其他路由 ...
            "unclear": "clarify_intent",
            "__end__": "__end__"
        }
    )
    
    # 修改回边：专门智能体 -> 并行回复审核 -> 路由节点
    router_graph.add_edge("blood_pressure_agent", "parallel_response_review")
    router_graph.add_edge("appointment_agent", "parallel_response_review")
    # ... 其他智能体 ...
    router_graph.add_edge("clarify_intent", "parallel_response_review")
    
    router_graph.add_edge("parallel_response_review", "router")
    
    # 编译图
    compiled_graph = router_graph.compile(checkpointer=checkpointer)
    
    logger.info("路由图创建成功（包含并行安全检查）")
    
    return compiled_graph
```

## 五、性能对比

### 5.1 延迟对比（假设）

假设各步骤耗时：
- 快速安全检查：50ms
- 敏感词检测：100ms（缓存）
- 用户行为分析：200ms
- 输入内容审核（LLM）：1000ms
- 路由智能体：500ms
- 专门智能体：2000ms
- 回复质量评估（LLM）：800ms
- 回复安全审核（LLM）：1000ms
- 医疗建议风险评估（LLM）：1200ms

**串行方案总延迟**：
```
50 + 100 + 200 + 1000 + 500 + 2000 + 800 + 1000 + 1200 = 6850ms
```

**并行方案总延迟**：
```
输入阶段并行：max(50, 100, 200, 1000) = 1000ms
主业务流程：500 + 2000 = 2500ms
回复审核并行：max(800, 1000, 1200) = 1200ms
总计：1000 + 2500 + 1200 = 4700ms
```

**性能提升**：约 31% 的延迟减少

### 5.2 资源利用率对比

- **串行方案**：资源利用率低，大部分时间在等待
- **并行方案**：资源利用率高，可以充分利用多核CPU和异步IO

## 六、实施建议

### 6.1 推荐实施路径

1. **第一阶段**：实现串行方案（当前方案）
   - 验证功能正确性
   - 建立基线性能指标

2. **第二阶段**：优化为混合方案
   - 关键安全检查保持同步
   - 非关键检查改为并行
   - 输入内容审核与主流程并行

3. **第三阶段**：全面并行化
   - 回复审核全面并行
   - 优化异步处理逻辑
   - 性能调优

### 6.2 注意事项

1. **错误处理**：并行执行时，需要妥善处理异常
2. **超时控制**：设置合理的超时时间，避免某个任务阻塞整体
3. **资源限制**：控制并发数量，避免资源耗尽
4. **结果一致性**：确保并行执行的结果一致性

## 七、总结

### 7.1 方案选择建议

**对于医疗AI系统，推荐使用混合方案**：

1. **关键安全检查**：同步执行，必须通过
2. **非关键检查**：并行执行，提高性能
3. **输入审核**：可以与主流程并行（如果审核失败，可以中断）
4. **回复审核**：并行执行，提高响应速度

### 7.2 主流性

- ✅ **并行执行是主流做法**：大多数现代AI系统都采用并行或混合方案
- ✅ **混合方案最受欢迎**：平衡了安全性和性能
- ✅ **LangGraph支持并行**：可以通过 `asyncio.gather` 在节点内部实现并行

### 7.3 优势

- ✅ **性能提升**：可以减少 20-40% 的响应时间
- ✅ **资源利用**：提高系统资源利用率
- ✅ **用户体验**：更快的响应速度，更好的用户体验
- ✅ **可扩展性**：易于添加新的并行检查项

---

**文档版本**：V1.0  
**创建时间**：2025-01-XX  
**维护者**：开发团队

