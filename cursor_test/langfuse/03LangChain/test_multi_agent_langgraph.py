"""
å¤šæ™ºèƒ½ä½“ LangGraph ä¸ Langfuse é›†æˆç¤ºä¾‹

åŠŸèƒ½è¯´æ˜ï¼š
1. åˆ›å»ºä¸€ä¸ªå¤šæ™ºèƒ½ä½“åº”ç”¨ï¼ŒåŒ…å«ï¼š
   - ä¸»æ™ºèƒ½ä½“ï¼ˆMain Agentï¼‰ï¼šä½¿ç”¨ ReAct æ¨¡å¼ï¼Œå¯ä»¥è°ƒç”¨å·¥å…·
   - å­æ™ºèƒ½ä½“ï¼ˆResearch Sub-Agentï¼‰ï¼šä¸“é—¨ç”¨äºç ”ç©¶ä»»åŠ¡çš„ LangGraph æ™ºèƒ½ä½“
   - ç ”ç©¶å·¥å…·ï¼ˆResearch Toolï¼‰ï¼šè°ƒç”¨å­æ™ºèƒ½ä½“è¿›è¡Œç ”ç©¶
2. é›†æˆ Langfuse è¿›è¡Œåˆ†å¸ƒå¼è¿½è¸ªï¼Œç¡®ä¿ä¸»æ™ºèƒ½ä½“å’Œå­æ™ºèƒ½ä½“çš„è¿½è¸ªå…³è”
3. ä» .env æ–‡ä»¶è¯»å–é…ç½®

å‚è€ƒæ–‡æ¡£ï¼š
https://langfuse.com/guides/cookbook/integration_langgraph#example-2-multi-agent-application-with-langgraph

è¿è¡Œæ–¹å¼ï¼š
ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼š
    python -m cursor_test.langfuse.03LangChain.test_multi_agent_langgraph
æˆ–ï¼š
    cd cursor_test/langfuse/03LangChain && python test_multi_agent_langgraph.py

ç¯å¢ƒå˜é‡é…ç½®ï¼ˆ.env æ–‡ä»¶ï¼‰ï¼š
    # Langfuse é…ç½®
    LANGFUSE_ENABLED=true
    LANGFUSE_PUBLIC_KEY=pk-lf-...
    LANGFUSE_SECRET_KEY=sk-lf-...
    LANGFUSE_HOST=https://cloud.langfuse.com  # å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ cloud.langfuse.com
    
    # LLM é…ç½®ï¼ˆè‡³å°‘é…ç½®ä¸€ä¸ªï¼‰
    OPENAI_API_KEY=sk-...
    # æˆ–
    DOUBAO_API_KEY=...
    # æˆ–
    DEEPSEEK_API_KEY=...
"""
import sys
import os
import secrets
import logging
from pathlib import Path
from typing import TypedDict, Annotated, Optional
from pydantic import Field
from pydantic_settings import BaseSettings, SettingsConfigDict


# ==================== é…ç½®ç®¡ç† ====================

def find_project_root() -> Path:
    """
    æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« .env æ–‡ä»¶çš„ç›®å½•ï¼‰
    """
    current = Path(__file__).resolve()
    # å½“å‰æ–‡ä»¶ä½äº cursor_test/langfuse/03LangChain/test_multi_agent_langgraph.py
    # é¡¹ç›®æ ¹ç›®å½•åº”è¯¥æ˜¯ current.parent.parent.parent
    project_root = current.parent.parent.parent
    
    # éªŒè¯é¡¹ç›®æ ¹ç›®å½•æ˜¯å¦å­˜åœ¨ .env æ–‡ä»¶
    env_file = project_root / ".env"
    if env_file.exists():
        return project_root
    
    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå‘ä¸ŠæŸ¥æ‰¾
    for parent in current.parents:
        env_file = parent / ".env"
        if env_file.exists():
            return parent
    
    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›è®¡ç®—å‡ºçš„é¡¹ç›®æ ¹ç›®å½•
    return project_root


class Settings(BaseSettings):
    """åº”ç”¨é…ç½®ï¼ˆä» .env æ–‡ä»¶è¯»å–ï¼‰"""
    
    model_config = SettingsConfigDict(
        env_file=find_project_root() / ".env",  # ä»é¡¹ç›®æ ¹ç›®å½•è¯»å–
        env_file_encoding="utf-8",
        case_sensitive=True,
        extra="ignore"
    )
    
    # Langfuse é…ç½®
    LANGFUSE_ENABLED: bool = Field(
        default=False,
        description="æ˜¯å¦å¯ç”¨Langfuseå¯è§‚æµ‹æ€§"
    )
    LANGFUSE_PUBLIC_KEY: Optional[str] = Field(
        default=None,
        description="Langfuseå…¬é’¥ï¼ˆä».envæ–‡ä»¶è¯»å–ï¼‰"
    )
    LANGFUSE_SECRET_KEY: Optional[str] = Field(
        default=None,
        description="Langfuseå¯†é’¥ï¼ˆä».envæ–‡ä»¶è¯»å–ï¼‰"
    )
    LANGFUSE_HOST: Optional[str] = Field(
        default=None,
        description="LangfuseæœåŠ¡å™¨åœ°å€ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨cloud.langfuse.comï¼‰"
    )
    
    # LLM é…ç½®
    OPENAI_API_KEY: Optional[str] = None
    OPENAI_BASE_URL: Optional[str] = None
    DOUBAO_API_KEY: Optional[str] = None
    DOUBAO_BASE_URL: Optional[str] = None
    DEEPSEEK_API_KEY: Optional[str] = None
    DEEPSEEK_BASE_URL: Optional[str] = None
    LLM_MODEL: str = Field(default="gpt-3.5-turbo", description="é»˜è®¤æ¨¡å‹åç§°")


# åˆ›å»ºå…¨å±€é…ç½®å®ä¾‹
settings = Settings()

# æ‰“å°é…ç½®åŠ è½½æƒ…å†µï¼ˆç”¨äºè°ƒè¯•ï¼‰
env_file_path = find_project_root() / ".env"
print(f"[é…ç½®] .env æ–‡ä»¶è·¯å¾„: {env_file_path}")
print(f"[é…ç½®] .env æ–‡ä»¶å­˜åœ¨: {env_file_path.exists()}")
print(f"[é…ç½®] LANGFUSE_ENABLED: {settings.LANGFUSE_ENABLED}")
print(f"[é…ç½®] LANGFUSE_PUBLIC_KEY: {'å·²è®¾ç½®' if settings.LANGFUSE_PUBLIC_KEY else 'æœªè®¾ç½®'}")
print(f"[é…ç½®] LANGFUSE_SECRET_KEY: {'å·²è®¾ç½®' if settings.LANGFUSE_SECRET_KEY else 'æœªè®¾ç½®'}")

# LangChain å’Œ LangGraph ç›¸å…³å¯¼å…¥
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from typing_extensions import TypedDict as LangGraphTypedDict

# Langfuse ç›¸å…³å¯¼å…¥
from langfuse import Langfuse, get_client
from langfuse.langchain import CallbackHandler

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ==================== Langfuse åˆå§‹åŒ– ====================

def init_langfuse() -> None:
    """
    åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯
    """
    public_key = settings.LANGFUSE_PUBLIC_KEY
    secret_key = settings.LANGFUSE_SECRET_KEY
    host = settings.LANGFUSE_HOST
    
    if not public_key or not secret_key:
        raise ValueError(
            "Langfuse é…ç½®ä¸å®Œæ•´ï¼šç¼ºå°‘ LANGFUSE_PUBLIC_KEY æˆ– LANGFUSE_SECRET_KEY"
        )
    
    # åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    langfuse_kwargs = {
        "public_key": public_key,
        "secret_key": secret_key,
    }
    if host:
        langfuse_kwargs["host"] = host
    
    Langfuse(**langfuse_kwargs)
    logger.info(f"Langfuse å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: host={host or 'default'}")


def create_langfuse_handler() -> CallbackHandler:
    """
    åˆ›å»º Langfuse CallbackHandler
    
    Returns:
        CallbackHandler: Langfuse å›è°ƒå¤„ç†å™¨
    """
    public_key = settings.LANGFUSE_PUBLIC_KEY
    if not public_key:
        raise ValueError("Langfuse é…ç½®ä¸å®Œæ•´ï¼šç¼ºå°‘ LANGFUSE_PUBLIC_KEY")
    
    # v3.x ç‰ˆæœ¬ï¼šåªéœ€è¦ public_keyï¼Œsecret_key é€šè¿‡å…¨å±€å®¢æˆ·ç«¯é…ç½®
    handler = CallbackHandler(public_key=public_key)
    logger.debug("Langfuse CallbackHandler åˆ›å»ºæˆåŠŸ")
    return handler


# ==================== LLM å®¢æˆ·ç«¯åˆ›å»º ====================

def create_llm() -> ChatOpenAI:
    """
    åˆ›å»º LLM å®¢æˆ·ç«¯
    
    æ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å–å¤šä¸ªä¾›åº”å•†çš„é…ç½®ï¼š
    - OPENAI_API_KEY + OPENAI_BASE_URL
    - DOUBAO_API_KEY + DOUBAO_BASE_URL
    - DEEPSEEK_API_KEY + DEEPSEEK_BASE_URL
    
    Returns:
        ChatOpenAI: LLM å®¢æˆ·ç«¯å®ä¾‹
        
    Raises:
        ValueError: å¦‚æœæœªé…ç½®ä»»ä½• API Key
    """
    # ä»é…ç½®è¯»å–ï¼ˆä½¿ç”¨ pydantic_settingsï¼Œè‡ªåŠ¨ä» .env æ–‡ä»¶åŠ è½½ï¼‰
    # ä¼˜å…ˆä½¿ç”¨ OPENAI_API_KEY
    api_key = settings.OPENAI_API_KEY
    base_url = settings.OPENAI_BASE_URL
    model = settings.LLM_MODEL
    
    # å¦‚æœæ²¡æœ‰ OPENAI_API_KEYï¼Œå°è¯•å…¶ä»–ä¾›åº”å•†
    if not api_key:
        api_key = settings.DOUBAO_API_KEY
        base_url = settings.DOUBAO_BASE_URL
        if not model or model == "gpt-3.5-turbo":  # å¦‚æœä½¿ç”¨é»˜è®¤å€¼ï¼Œæ”¹ä¸ºè±†åŒ…é»˜è®¤å€¼
            model = "doubao-seed-1-6-251015"
    
    if not api_key:
        api_key = settings.DEEPSEEK_API_KEY
        base_url = settings.DEEPSEEK_BASE_URL
        if not model or model == "gpt-3.5-turbo":  # å¦‚æœä½¿ç”¨é»˜è®¤å€¼ï¼Œæ”¹ä¸º DeepSeek é»˜è®¤å€¼
            model = "deepseek-chat"
    
    if not api_key:
        raise ValueError(
            "æœªé…ç½® LLM API Keyã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹ä¹‹ä¸€ï¼š\n"
            "  - OPENAI_API_KEY\n"
            "  - DOUBAO_API_KEY\n"
            "  - DEEPSEEK_API_KEY"
        )
    
    # åˆ›å»º Langfuse Handler
    langfuse_handler = create_langfuse_handler()
    
    # åˆ›å»º LLM å®¢æˆ·ç«¯
    llm = ChatOpenAI(
        model=model,
        openai_api_key=api_key,
        openai_api_base=base_url,
        temperature=0.7,
        callbacks=[langfuse_handler]
    )
    
    logger.info(f"åˆ›å»º LLM å®¢æˆ·ç«¯: model={model}, base_url={base_url or 'default'}")
    return llm


# ==================== å­æ™ºèƒ½ä½“ï¼ˆResearch Sub-Agentï¼‰åˆ›å»º ====================

class SubAgentState(LangGraphTypedDict):
    """å­æ™ºèƒ½ä½“çŠ¶æ€å®šä¹‰"""
    messages: Annotated[list, add_messages]


def build_research_sub_agent() -> StateGraph:
    """
    æ„å»ºç ”ç©¶å­æ™ºèƒ½ä½“ï¼ˆResearch Sub-Agentï¼‰
    
    è¿™æ˜¯ä¸€ä¸ªç®€å•çš„ LangGraph æ™ºèƒ½ä½“ï¼Œä¸“é—¨ç”¨äºå›ç­”ç ”ç©¶ç±»é—®é¢˜ã€‚
    
    Returns:
        StateGraph: ç¼–è¯‘åçš„å­æ™ºèƒ½ä½“å›¾
    """
    logger.info("[å­æ™ºèƒ½ä½“] å¼€å§‹æ„å»ºç ”ç©¶å­æ™ºèƒ½ä½“...")
    
    # åˆ›å»ºå›¾
    graph_builder = StateGraph(SubAgentState)
    
    # åˆ›å»º LLM
    llm = create_llm()
    
    # å®šä¹‰èŠå¤©èŠ‚ç‚¹
    def chatbot(state: SubAgentState):
        """èŠå¤©èŠ‚ç‚¹ï¼šä½¿ç”¨ LLM ç”Ÿæˆå›å¤"""
        messages = state.get("messages", [])
        response = llm.invoke(messages)
        return {"messages": [response]}
    
    # æ·»åŠ èŠ‚ç‚¹
    graph_builder.add_node("chatbot", chatbot)
    
    # è®¾ç½®å…¥å£å’Œç»“æŸç‚¹
    graph_builder.set_entry_point("chatbot")
    graph_builder.set_finish_point("chatbot")
    
    # ç¼–è¯‘å›¾
    checkpoint = MemorySaver()
    sub_agent = graph_builder.compile(checkpointer=checkpoint)
    
    logger.info("[å­æ™ºèƒ½ä½“] ç ”ç©¶å­æ™ºèƒ½ä½“æ„å»ºå®Œæˆ")
    return sub_agent


# ==================== å·¥å…·å®šä¹‰ ====================

def create_research_tool(sub_agent: StateGraph, langfuse_handler: CallbackHandler, trace_id: str):
    """
    åˆ›å»ºç ”ç©¶å·¥å…·ï¼Œè¯¥å·¥å…·è°ƒç”¨å­æ™ºèƒ½ä½“è¿›è¡Œç ”ç©¶
    
    Args:
        sub_agent: ç ”ç©¶å­æ™ºèƒ½ä½“å›¾
        langfuse_handler: Langfuse å›è°ƒå¤„ç†å™¨
        trace_id: è¿½è¸ª IDï¼Œç”¨äºå…³è”åˆ†å¸ƒå¼è¿½è¸ª
        
    Returns:
        å·¥å…·å‡½æ•°
    """
    # ä½¿ç”¨é—­åŒ…æ•è·å¤–éƒ¨å˜é‡ï¼Œåˆ›å»ºå·¥å…·å‡½æ•°
    @tool
    def langgraph_research(question: str) -> str:
        """
        è¿›è¡Œç ”ç©¶ï¼Œå›ç­”å„ç§ä¸»é¢˜çš„é—®é¢˜ã€‚
        
        Args:
            question: è¦ç ”ç©¶çš„é—®é¢˜
            
        Returns:
            str: ç ”ç©¶ç»“æœ
        """
        logger.info(f"[ç ”ç©¶å·¥å…·] å¼€å§‹ç ”ç©¶é—®é¢˜: {question[:50]}...")
        
        langfuse = get_client()
        
        # ä½¿ç”¨ start_as_current_observation åˆ›å»ºå­è¿½è¸ªï¼Œå…³è”åˆ°ä¸»è¿½è¸ª
        with langfuse.start_as_current_observation(
            name="ğŸ¤–-sub-research-agent",
            trace_context={"trace_id": trace_id}
        ) as observation:
            # æ›´æ–°è¿½è¸ªè¾“å…¥
            observation.update_trace(input=question)
            
            # è°ƒç”¨å­æ™ºèƒ½ä½“
            response = sub_agent.invoke(
                {"messages": [HumanMessage(content=question)]},
                config={"callbacks": [langfuse_handler]}
            )
            
            # æå–å›å¤å†…å®¹
            response_content = ""
            messages = response.get("messages", [])
            if messages and len(messages) > 0:
                # è·å–æœ€åä¸€æ¡ AI æ¶ˆæ¯
                for msg in reversed(messages):
                    if hasattr(msg, "content"):
                        response_content = msg.content
                        break
            
            # æ›´æ–°è¿½è¸ªè¾“å‡º
            observation.update_trace(output=response_content)
            
            logger.info(f"[ç ”ç©¶å·¥å…·] ç ”ç©¶å®Œæˆ: {response_content[:100]}...")
            return response_content
    
    return langgraph_research


# ==================== ä¸»æ™ºèƒ½ä½“åˆ›å»º ====================

def create_main_agent(tools: list, langfuse_handler: CallbackHandler) -> StateGraph:
    """
    åˆ›å»ºä¸»æ™ºèƒ½ä½“ï¼ˆMain Agentï¼‰
    
    ä½¿ç”¨ create_react_agent åˆ›å»ºä¸€ä¸ª ReAct æ¨¡å¼çš„æ™ºèƒ½ä½“ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·ã€‚
    
    Args:
        tools: å·¥å…·åˆ—è¡¨
        langfuse_handler: Langfuse å›è°ƒå¤„ç†å™¨
        
    Returns:
        StateGraph: ç¼–è¯‘åçš„ä¸»æ™ºèƒ½ä½“å›¾
    """
    logger.info("[ä¸»æ™ºèƒ½ä½“] å¼€å§‹åˆ›å»ºä¸»æ™ºèƒ½ä½“...")
    
    # åˆ›å»º LLM
    llm = create_llm()
    
    # ä½¿ç”¨ create_react_agent åˆ›å»ºä¸»æ™ºèƒ½ä½“
    main_agent = create_react_agent(
        model=llm,
        tools=tools
    )
    
    logger.info(f"[ä¸»æ™ºèƒ½ä½“] ä¸»æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆï¼Œå·¥å…·æ•°é‡: {len(tools)}")
    return main_agent


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("å¤šæ™ºèƒ½ä½“ LangGraph ä¸ Langfuse é›†æˆç¤ºä¾‹")
    logger.info("=" * 80)
    
    # 1. åˆå§‹åŒ– Langfuse
    logger.info("[æ­¥éª¤1] åˆå§‹åŒ– Langfuse...")
    init_langfuse()
    logger.info("[æ­¥éª¤1] Langfuse åˆå§‹åŒ–æˆåŠŸ")
    
    # 2. åˆ›å»º Langfuse Handler
    langfuse_handler = create_langfuse_handler()
    
    # 3. æ„å»ºå­æ™ºèƒ½ä½“
    logger.info("[æ­¥éª¤2] æ„å»ºç ”ç©¶å­æ™ºèƒ½ä½“...")
    sub_agent = build_research_sub_agent()
    logger.info("[æ­¥éª¤2] ç ”ç©¶å­æ™ºèƒ½ä½“æ„å»ºå®Œæˆ")
    
    # 4. ç”Ÿæˆè¿½è¸ª IDï¼ˆç”¨äºåˆ†å¸ƒå¼è¿½è¸ªï¼‰
    trace_id = secrets.token_hex(16)
    logger.info(f"[æ­¥éª¤3] ç”Ÿæˆè¿½è¸ª ID: {trace_id}")
    
    # 5. åˆ›å»ºç ”ç©¶å·¥å…·
    logger.info("[æ­¥éª¤4] åˆ›å»ºç ”ç©¶å·¥å…·...")
    research_tool = create_research_tool(sub_agent, langfuse_handler, trace_id)
    logger.info("[æ­¥éª¤4] ç ”ç©¶å·¥å…·åˆ›å»ºå®Œæˆ")
    
    # 6. åˆ›å»ºä¸»æ™ºèƒ½ä½“
    logger.info("[æ­¥éª¤5] åˆ›å»ºä¸»æ™ºèƒ½ä½“...")
    main_agent = create_main_agent(tools=[research_tool], langfuse_handler=langfuse_handler)
    logger.info("[æ­¥éª¤5] ä¸»æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ")
    
    # 7. æ‰§è¡Œä¸»æ™ºèƒ½ä½“ï¼ˆä½¿ç”¨ Langfuse è¿½è¸ªï¼‰
    langfuse = get_client()
    
    # ä½¿ç”¨ start_as_current_observation åˆ›å»ºä¸»è¿½è¸ª
    with langfuse.start_as_current_observation(
        name="ğŸ¤–-main-agent",
        trace_context={"trace_id": trace_id}
    ) as observation:
        # æ›´æ–°è¿½è¸ªå…ƒæ•°æ®
        langfuse.update_current_trace(
            name="multi-agent-langgraph-example",
            user_id="test_user",
            session_id="test_session",
            metadata={
                "example": "multi_agent_langgraph_integration",
                "agent_type": "multi-agent"
            }
        )
        
        # å‡†å¤‡ç”¨æˆ·é—®é¢˜
        user_question = "ä»€ä¹ˆæ˜¯ Langfuseï¼Ÿ"
        logger.info(f"[æ­¥éª¤6] ç”¨æˆ·é—®é¢˜: {user_question}")
        
        # æ›´æ–°è¿½è¸ªè¾“å…¥
        observation.update_trace(input=user_question)
        
        # è°ƒç”¨ä¸»æ™ºèƒ½ä½“
        logger.info("[æ­¥éª¤6] å¼€å§‹æ‰§è¡Œä¸»æ™ºèƒ½ä½“...")
        logger.info("-" * 80)
        
        response = main_agent.invoke(
            {"messages": [{"role": "user", "content": user_question}]},
            config={"callbacks": [langfuse_handler]}
        )
        
        logger.info("-" * 80)
        logger.info("[æ­¥éª¤6] ä¸»æ™ºèƒ½ä½“æ‰§è¡Œå®Œæˆ")
        
        # æå–å›å¤å†…å®¹
        response_content = ""
        messages = response.get("messages", [])
        if messages:
            # è·å–æœ€åä¸€æ¡ AI æ¶ˆæ¯
            for msg in reversed(messages):
                if hasattr(msg, "content"):
                    response_content = msg.content
                    break
        
        # æ›´æ–°è¿½è¸ªè¾“å‡º
        observation.update_trace(output=response_content)
        
        # 8. æ˜¾ç¤ºç»“æœ
        logger.info("[æ­¥éª¤7] æ‰§è¡Œç»“æœ:")
        logger.info(f"  ç”¨æˆ·é—®é¢˜: {user_question}")
        logger.info(f"  AI å›å¤: {response_content[:200]}...")
        
        # 9. åˆ·æ–° Langfuse äº‹ä»¶
        logger.info("[æ­¥éª¤8] åˆ·æ–° Langfuse äº‹ä»¶...")
        langfuse.flush()
        logger.info("[æ­¥éª¤8] Langfuse äº‹ä»¶å·²åˆ·æ–°")
        
        logger.info("=" * 80)
        logger.info("ç¤ºä¾‹æ‰§è¡Œå®Œæˆ")
        logger.info(f"Trace ID: {trace_id}")
        logger.info("è¯·åœ¨ Langfuse UI ä¸­æŸ¥çœ‹è¿½è¸ªè®°å½•")
        logger.info("=" * 80)


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)

